{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.myutils import save_object, load_object\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_records_per_class = 50\n",
    "max_upsampling_factor = 20\n",
    "save_models = False\n",
    "max_sample = None\n",
    "only_train_on_entire_set = False #Works only with previously stored confidence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_training(df, opt_params=False):\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = df[df.Label==False]\n",
    "    df_minority = df[df.Label==True]\n",
    "    \n",
    "    if df_majority.shape[0] < min_records_per_class or df_minority.shape[0] < min_records_per_class:\n",
    "        return None\n",
    "    \n",
    "    if df_majority.shape[0] == df_minority.shape[0]:\n",
    "        return df\n",
    "    \n",
    "    if not opt_params:\n",
    "        print(\"Resampling (\" + str(df_majority.shape[0]) + \",\" + str(df_minority.shape[0]) + \")\")\n",
    "    \n",
    "    #Will probably not occur but who knows...\n",
    "    if df_majority.shape[0] < df_minority.shape[0]:\n",
    "        print(\"Strange Format!\")\n",
    "        df_majority = df[df.Label==True]\n",
    "        df_minority = df[df.Label==False]\n",
    "    \n",
    "    n_samples_new = df_majority.shape[0]\n",
    "    if n_samples_new > (df_minority.shape[0] * max_upsampling_factor):\n",
    "        n_samples_new = df_minority.shape[0] * max_upsampling_factor\n",
    "        \n",
    "    # Upsample minority class\n",
    "    df_minority_resampled = resample(df_minority, \n",
    "                                     replace=True,            # sample with replacement\n",
    "                                     n_samples=n_samples_new, # to match majority class\n",
    "                                     random_state=123)        # reproducible results\n",
    "    \n",
    "    #Maximum Upsampling reached - Downsampling the rest\n",
    "    if not df_majority.shape[0] == df_minority_resampled.shape[0]:\n",
    "        df_majority_resampled = resample(df_majority, \n",
    "                                         replace=True,                             # sample with replacement\n",
    "                                         n_samples=df_minority_resampled.shape[0], # to match minority class\n",
    "                                         random_state=123)                         # reproducible results\n",
    "    else:\n",
    "        df_majority_resampled = df_majority\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority_resampled, df_minority_resampled])\n",
    "\n",
    "    # Display new class counts\n",
    "    #print(df_upsampled.Label.value_counts())\n",
    "    if not opt_params:\n",
    "        print(\"Resampled to (\" + str(df_majority_resampled.shape[0]) + \",\" + str(df_minority_resampled.shape[0]) + \")\")\n",
    "    return df_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance( labels_actual, labels_predicted ):\n",
    "    accur = accuracy_score(labels_actual, labels_predicted)\n",
    "    conf_matrix = confusion_matrix(labels_actual, labels_predicted)\n",
    "    class_report = classification_report(labels_actual, labels_predicted)\n",
    "    \n",
    "    print(\"Accuracy: \" + str( accur ))\n",
    "    print()\n",
    "    try:\n",
    "        print(\"             Predicted False \\t Predicted True\")\n",
    "        print(\"Actual False \" + str( conf_matrix[0][0] ) + \"  \\t\\t \" + str( conf_matrix[0][1] ))\n",
    "        print(\"Actual True  \" + str( conf_matrix[1][0] ) + \"  \\t\\t \" + str( conf_matrix[1][1] ))\n",
    "    except IndexError:\n",
    "        print('WARNING: Just a single class has been found!')\n",
    "        print(conf_matrix)\n",
    "    print()\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_list(list_to_check):\n",
    "    count_true = 0\n",
    "    count_false = 0\n",
    "    #Count True\n",
    "    for elem in list_to_check:\n",
    "        if elem == True:\n",
    "            count_true += 1\n",
    "        if count_true >= min_records_per_class:\n",
    "            for elem in list_to_check:\n",
    "                if elem == False:\n",
    "                    count_false += 1\n",
    "                if count_false >= min_records_per_class:\n",
    "                    return True\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---area.csv---\n",
      "96 True instances (25966 in total -> 0.3697142417006855 %)\n",
      "Resampling (19402,72)\n",
      "Resampled to (1440,1440)\n",
      "Length of Test: 6492\n",
      "For confidence 0.5 reduced to 6492. Precision: 0.078125\n",
      "No model could be found! (Minimum number of true examples reached)\n",
      "---areaLand.csv---\n",
      "2 True instances (131097 in total -> 0.001525587923445998 %)\n",
      "Not enough data\n",
      "---areaTotal.csv---\n",
      "92 True instances (410292 in total -> 0.022423054799996102 %)\n",
      "Resampling (307650,69)\n",
      "Resampled to (1380,1380)\n",
      "Length of Test: 102573\n",
      "For confidence 0.5 reduced to 102573. Precision: 0.020021074815595362\n",
      "No model could be found! (Minimum number of true examples reached)\n",
      "---areaWater.csv---\n",
      "83 True instances (125117 in total -> 0.0663379077183756 %)\n",
      "Resampling (93775,62)\n",
      "Resampled to (1240,1240)\n",
      "Length of Test: 31280\n",
      "For confidence 0.5 reduced to 31280. Precision: 0.010626992561105207\n",
      "No model could be found! (Minimum number of true examples reached)\n",
      "---elevation.csv---\n",
      "18576 True instances (398376 in total -> 4.662931501897704 %)\n",
      "Resampling (284850,13932)\n",
      "Resampled to (278640,278640)\n",
      "Sampled train to 20000\n",
      "Length of Test: 99594\n",
      "For confidence 0.5 reduced to 99594. Precision: 0.5530625402965829\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.961634234994076\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 91484  \t\t 3466\n",
      "Actual True  355  \t\t 4289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98     94950\n",
      "        True       0.55      0.92      0.69      4644\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     99594\n",
      "   macro avg       0.77      0.94      0.84     99594\n",
      "weighted avg       0.98      0.96      0.97     99594\n",
      "\n",
      "---height.csv---\n",
      "3136 True instances (42900 in total -> 7.31002331002331 %)\n",
      "Resampling (29823,2352)\n",
      "Resampled to (29823,29823)\n",
      "Sampled train to 20000\n",
      "Length of Test: 10725\n",
      "For confidence 0.5 reduced to 10725. Precision: 0.744258872651357\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9705361305361305\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 9696  \t\t 245\n",
      "Actual True  71  \t\t 713\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.98      9941\n",
      "        True       0.74      0.91      0.82       784\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10725\n",
      "   macro avg       0.87      0.94      0.90     10725\n",
      "weighted avg       0.97      0.97      0.97     10725\n",
      "\n",
      "---length.csv---\n",
      "1670 True instances (114498 in total -> 1.458540760537302 %)\n",
      "Resampling (84621,1252)\n",
      "Resampled to (25040,25040)\n",
      "Sampled train to 20000\n",
      "Length of Test: 28625\n",
      "For confidence 0.5 reduced to 28625. Precision: 0.3787878787878788\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9775720524017467\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 27633  \t\t 574\n",
      "Actual True  68  \t\t 350\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99     28207\n",
      "        True       0.38      0.84      0.52       418\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     28625\n",
      "   macro avg       0.69      0.91      0.76     28625\n",
      "weighted avg       0.99      0.98      0.98     28625\n",
      "\n",
      "---maximumElevation.csv---\n",
      "283 True instances (19599 in total -> 1.4439512220011224 %)\n",
      "Resampling (14487,212)\n",
      "Resampled to (4240,4240)\n",
      "Length of Test: 4900\n",
      "For confidence 0.5 reduced to 4900. Precision: 0.32116788321167883\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9755102040816327\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 4736  \t\t 93\n",
      "Actual True  27  \t\t 44\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.99      4829\n",
      "        True       0.32      0.62      0.42        71\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4900\n",
      "   macro avg       0.66      0.80      0.71      4900\n",
      "weighted avg       0.98      0.98      0.98      4900\n",
      "\n",
      "---minimumElevation.csv---\n",
      "156 True instances (18116 in total -> 0.8611172444248179 %)\n",
      "Resampling (13470,117)\n",
      "Resampled to (2340,2340)\n",
      "Length of Test: 4529\n",
      "For confidence 0.5 reduced to 4529. Precision: 0.06842105263157895\n",
      "No model could be found! (Minimum number of true examples reached)\n",
      "---numberOfEpisodes.csv---\n",
      "6418 True instances (150537 in total -> 4.263403681486944 %)\n",
      "Resampling (108089,4813)\n",
      "Resampled to (96260,96260)\n",
      "Sampled train to 20000\n",
      "Length of Test: 37635\n",
      "For confidence 0.5 reduced to 37635. Precision: 0.3565337001375516\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9296399628005846\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 33691  \t\t 2339\n",
      "Actual True  309  \t\t 1296\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.94      0.96     36030\n",
      "        True       0.36      0.81      0.49      1605\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     37635\n",
      "   macro avg       0.67      0.87      0.73     37635\n",
      "weighted avg       0.96      0.93      0.94     37635\n",
      "\n",
      "---numberOfGoals.csv---\n",
      "81 True instances (12146 in total -> 0.6668862176848345 %)\n",
      "Resampling (9048,61)\n",
      "Resampled to (1220,1220)\n",
      "Length of Test: 3037\n",
      "For confidence 0.5 reduced to 3037. Precision: 0.00784313725490196\n",
      "No model could be found! (Minimum number of true examples reached)\n",
      "---numberOfMatches.csv---\n",
      "No data\n",
      "---numberOfStudents.csv---\n",
      "6213 True instances (134831 in total -> 4.607990743968375 %)\n",
      "Resampling (96463,4660)\n",
      "Resampled to (93200,93200)\n",
      "Sampled train to 20000\n",
      "Length of Test: 33708\n",
      "For confidence 0.5 reduced to 33708. Precision: 0.32368896925858953\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9134330129346149\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 29537  \t\t 2618\n",
      "Actual True  300  \t\t 1253\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.92      0.95     32155\n",
      "        True       0.32      0.81      0.46      1553\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     33708\n",
      "   macro avg       0.66      0.86      0.71     33708\n",
      "weighted avg       0.96      0.91      0.93     33708\n",
      "\n",
      "---populationDensity.csv---\n",
      "1626 True instances (40307 in total -> 4.034038752573994 %)\n",
      "Resampling (29011,1219)\n",
      "Resampled to (24380,24380)\n",
      "Sampled train to 20000\n",
      "Length of Test: 10077\n",
      "For confidence 0.5 reduced to 10077. Precision: 0.8132118451025057\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9869008633521882\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 9588  \t\t 82\n",
      "Actual True  50  \t\t 357\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      9670\n",
      "        True       0.81      0.88      0.84       407\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10077\n",
      "   macro avg       0.90      0.93      0.92     10077\n",
      "weighted avg       0.99      0.99      0.99     10077\n",
      "\n",
      "---populationTotal.csv---\n",
      "191220 True instances (930058 in total -> 20.560008085517246 %)\n",
      "Resampling (554128,143415)\n",
      "Resampled to (554128,554128)\n",
      "Sampled train to 20000\n",
      "Length of Test: 232515\n",
      "For confidence 0.5 reduced to 232515. Precision: 0.8701929487057389\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9615766724727437\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 177895  \t\t 6815\n",
      "Actual True  2119  \t\t 45686\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.98    184710\n",
      "        True       0.87      0.96      0.91     47805\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    232515\n",
      "   macro avg       0.93      0.96      0.94    232515\n",
      "weighted avg       0.96      0.96      0.96    232515\n",
      "\n",
      "---runtime.csv---\n",
      "3304 True instances (927570 in total -> 0.3561995321107841 %)\n",
      "Resampling (693199,2478)\n",
      "Resampled to (49560,49560)\n",
      "Sampled train to 20000\n",
      "Length of Test: 231893\n",
      "For confidence 0.5 reduced to 231893. Precision: 0.022252352847344073\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.8931144967722182\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 206549  \t\t 24518\n",
      "Actual True  268  \t\t 558\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.89      0.94    231067\n",
      "        True       0.02      0.68      0.04       826\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    231893\n",
      "   macro avg       0.51      0.78      0.49    231893\n",
      "weighted avg       1.00      0.89      0.94    231893\n",
      "\n",
      "---runwayLength.csv---\n",
      "894 True instances (49725 in total -> 1.79788838612368 %)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling (36623,670)\n",
      "Resampled to (13400,13400)\n",
      "Sampled train to 20000\n",
      "Length of Test: 12432\n",
      "For confidence 0.5 reduced to 12432. Precision: 0.22365591397849463\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9613095238095238\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 11847  \t\t 361\n",
      "Actual True  120  \t\t 104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98     12208\n",
      "        True       0.22      0.46      0.30       224\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     12432\n",
      "   macro avg       0.61      0.72      0.64     12432\n",
      "weighted avg       0.98      0.96      0.97     12432\n",
      "\n",
      "---shipBeam.csv---\n",
      "279 True instances (12540 in total -> 2.2248803827751193 %)\n",
      "Resampling (9196,209)\n",
      "Resampled to (4180,4180)\n",
      "Length of Test: 3135\n",
      "For confidence 0.5 reduced to 3135. Precision: 0.46808510638297873\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.9757575757575757\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 3015  \t\t 50\n",
      "Actual True  26  \t\t 44\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.99      3065\n",
      "        True       0.47      0.63      0.54        70\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3135\n",
      "   macro avg       0.73      0.81      0.76      3135\n",
      "weighted avg       0.98      0.98      0.98      3135\n",
      "\n",
      "---squadNumber.csv---\n",
      "580 True instances (58310 in total -> 0.9946835877208026 %)\n",
      "Resampling (43297,435)\n",
      "Resampled to (8700,8700)\n",
      "Length of Test: 14578\n",
      "For confidence 0.5 reduced to 14578. Precision: 0.005885237861696911\n",
      "Model found at confidence 0.5\n",
      "Accuracy: 0.7136095486349293\n",
      "\n",
      "             Predicted False \t Predicted True\n",
      "Actual False 10379  \t\t 4054\n",
      "Actual True  121  \t\t 24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.72      0.83     14433\n",
      "        True       0.01      0.17      0.01       145\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     14578\n",
      "   macro avg       0.50      0.44      0.42     14578\n",
      "weighted avg       0.98      0.71      0.82     14578\n",
      "\n",
      "---weight.csv---\n",
      "73 True instances (397556 in total -> 0.018362192999225268 %)\n",
      "Resampling (298112,55)\n",
      "Resampled to (1100,1100)\n",
      "Length of Test: 99389\n",
      "For confidence 0.5 reduced to 99389. Precision: 0.009357454772301934\n",
      "No model could be found! (Minimum number of true examples reached)\n"
     ]
    }
   ],
   "source": [
    "directory = os.fsencode(\"data\")\n",
    "directory_name = directory.decode(\"utf-8\")\n",
    "\n",
    "#Paramter\n",
    "opt_params = False\n",
    "\n",
    "opt_params_relevant = ['elevation', 'height', 'numberOfEpisodes', 'numberOfStudents', 'populationDensity', 'populationTotal']\n",
    "opt_params_ddict = dict()\n",
    "\n",
    "param_grid = { 'criterion': ['gini','entropy'],\n",
    "               'max_depth': [20,40,100,None],\n",
    "               'min_samples_split': [10,20,40,80,160],\n",
    "               'min_samples_leaf': [1,5,20,100],\n",
    "               'min_impurity_decrease': [0.0, 0.000001, 0.01] }\n",
    "\n",
    "#Random Forest & Extra Trees\n",
    "param_grid = { 'n_estimators': [20,10],\n",
    "               'criterion': ['gini','entropy'],\n",
    "               'max_depth': [20,80,None],\n",
    "               'min_samples_split': [2,8,20,100],\n",
    "               'min_samples_leaf': [1,5,20,50],\n",
    "               'min_impurity_decrease': [0.0, 0.000001, 0.01] }\n",
    "\n",
    "#Bagging\n",
    "param_grid = { 'n_estimators': [20,10],\n",
    "               'max_features': [0.1,0.2,0.5,0.8,1.0],\n",
    "               'max_samples': [0.1,0.2,0.5,0.8,1.0],\n",
    "               'bootstrap': [True, False],\n",
    "               'bootstrap_features': [True, False] }\n",
    "\n",
    "#Adaboost\n",
    "param_grid = { 'n_estimators': [20,50,100,200],\n",
    "               'learning_rate': [0.001,0.01,0.1,0.2,0.4,0.6,0.8,1.0] }\n",
    "\n",
    "param_grid = { 'n_estimators': [2,24,48,64,72,96,128,192] }\n",
    "\n",
    "best_avg_precision = 0.0\n",
    "precisions = list()\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "  \n",
    "    if opt_params:\n",
    "        print('----------')\n",
    "        print('Parameters: ' + str( params ))\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        file_name = os.fsdecode(file)\n",
    "        if not file_name.endswith(\".csv\"):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #Only optimize on interesting relations\n",
    "        if opt_params and file_name[:-4] not in opt_params_relevant:\n",
    "            continue\n",
    "        \n",
    "        print('---' + file_name + '---')\n",
    "        \n",
    "        if only_train_on_entire_set:\n",
    "            try:\n",
    "                load_object('models/' + file_name[:-4] + '_confidence')\n",
    "            except FileNotFoundError:\n",
    "                print(\"No confidence threshold for \" + file_name)\n",
    "                continue\n",
    "        \n",
    "        if not opt_params or file_name not in opt_params_ddict:\n",
    "\n",
    "            try:\n",
    "                dtypes = load_object('data_info/' + file_name[:-4] + '_dtypes')\n",
    "                if type(dtypes) != dict:\n",
    "                    dtypes = dtypes.to_dict()\n",
    "            except (FileNotFoundError, AttributeError):\n",
    "                print('WARNING! No dtype information available!')\n",
    "                dtypes = None\n",
    "\n",
    "            data = pd.read_csv(directory_name + \"/\" + file_name,\n",
    "                               encoding = \"utf-8\",\n",
    "                               dtype = dtypes,\n",
    "                               sep = ',')\n",
    "            opt_params_ddict[file_name] = data\n",
    "            \n",
    "        else:\n",
    "            data = opt_params_ddict[file_name]\n",
    "\n",
    "        \n",
    "        \n",
    "        #Drop Info-Features\n",
    "        info_features = [col for col in list(data.columns) if col.startswith('Info')]\n",
    "        data_info = data[info_features]\n",
    "        data = data.drop(info_features, axis=1)\n",
    "        \n",
    "        #Some algorithms have problems with certain characters in feature names\n",
    "        data.columns = [re.sub('[\\[\\]<>]', 'X', elem) for elem in data.columns]\n",
    "        \n",
    "        #TODO!!\n",
    "        #data['StandardDeviationFactor'] = data['StandardDeviationFactor'].apply(abs)        \n",
    "        \n",
    "        if(data.shape[0] == 0):\n",
    "            if not opt_params:\n",
    "                print(\"No data\")\n",
    "            continue\n",
    "\n",
    "        if not opt_params:\n",
    "            prt_true_ins = data[data[\"Label\"] == True].shape[0]\n",
    "            prt_all_ins = data.shape[0]\n",
    "            print(str(prt_true_ins) + \" True instances (\" + str(prt_all_ins) + \" in total -> \" + str(prt_true_ins / prt_all_ins * 100) + \" %)\")\n",
    "        \n",
    "        #print(str(data[data[\"Label\"] == True].shape[0] / data.shape[0]) + \" %\")\n",
    "\n",
    "        if not only_train_on_entire_set:\n",
    "            try:\n",
    "                train_test_data = train_test_split(data, test_size=0.25, random_state=123, stratify=data['Label'])\n",
    "            except ValueError:\n",
    "                train_test_data = train_test_split(data, test_size=0.25, random_state=123)\n",
    "                print('ValueError while splitting train/test data! No stratified sampling applied!')\n",
    "            train_data = train_test_data[0]\n",
    "            test_data = train_test_data[1]\n",
    "        else:\n",
    "            train_data = data\n",
    "        \n",
    "        #print(str(train_data[train_data[\"Label\"] == True].shape[0] / train_data.shape[0]) + \" %\")\n",
    "        #print(str(test_data[test_data[\"Label\"] == True].shape[0] / test_data.shape[0]) + \" %\")\n",
    "        \n",
    "        train_data = balance_training(train_data, opt_params)\n",
    "        if(train_data is None):\n",
    "            if not opt_params:\n",
    "                print(\"Not enough data\")\n",
    "            continue\n",
    "            \n",
    "        if max_sample is not None and train_data.shape[0] > max_sample:\n",
    "            train_data = train_data.sample(n=max_sample, random_state=123)\n",
    "            print(\"Sampled train to \" + str(max_sample))\n",
    "\n",
    "        train_labels = train_data[\"Label\"].tolist()\n",
    "        train_data = train_data.drop(\"Label\", axis=1)\n",
    "        if not only_train_on_entire_set:\n",
    "            test_labels = test_data[\"Label\"].tolist()\n",
    "            test_data = test_data.drop(\"Label\", axis=1)\n",
    "            \n",
    "            if not valid_list(test_labels):\n",
    "                print('Not enough data')\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        #Normalize Features to mean 0 and variance 1\n",
    "        #scaler = StandardScaler()\n",
    "        #scaler.fit(train_data)  # Don't cheat - fit only on training data\n",
    "        #train_data = scaler.transform(train_data)\n",
    "        #test_data = scaler.transform(test_data)  # apply same transformation to test data\n",
    "\n",
    "        #Old: {'criterion': 'gini', 'max_depth': 1000, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
    "        base_learner = DecisionTreeClassifier(criterion='entropy', max_depth=80, min_impurity_decrease=1e-06, min_samples_leaf=1, min_samples_split=10, random_state=123)\n",
    "        #learner = base_learner\n",
    "        \n",
    "        #learner = SGDClassifier(loss='log', max_iter=np.ceil(10**6 / len(train_labels)), random_state=123)\n",
    "        #learner = MultinomialNB()\n",
    "        #learner = SVC(C=0.8, cache_size=4000, probability=True)\n",
    "        learner = RandomForestClassifier(n_estimators=96, criterion='gini', max_depth=80, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, random_state=123)\n",
    "        #learner = ExtraTreesClassifier(n_estimators=20, criterion='entropy', max_depth=80, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=8, random_state=123)\n",
    "        #learner = BaggingClassifier(base_learner, bootstrap=False, bootstrap_features=False, max_samples=1.0, max_features=0.5, n_estimators=20, random_state=123)\n",
    "        #learner = AdaBoostClassifier(n_estimators=200, random_state=123)\n",
    "        #learner = XGBClassifier(n_estimators=2000, learning_rate=0.4, max_depth=20, min_child_weight=1, gamma=0.15, subsample=0.95, colsample_bytree=0.65, scale_pos_weight=1, reg_lambda=0.9, reg_alpha=1e-5, random_state=123)\n",
    "        \n",
    "        if opt_params:\n",
    "            learner.set_params(**params)\n",
    "        learner = learner.fit(train_data, train_labels)\n",
    "\n",
    "        \n",
    "        if only_train_on_entire_set:\n",
    "            save_object(learner, 'models/' + file_name[:-4]) #Strip \".csv\"\n",
    "            save_object(train_data.columns, 'models/' + file_name[:-4] + '_features')\n",
    "            print('Successfully stored new model and columns.')\n",
    "        \n",
    "        #feature_importances_dict = dict()\n",
    "        #feature_importances = learner.feature_importances_\n",
    "        #\n",
    "        #for i, fi in enumerate(feature_importances):\n",
    "        #    feature_importances_dict[data.columns[i]] = fi\n",
    "        # \n",
    "        #print(sorted( ((v,k) for k,v in feature_importances_dict.items()), reverse=True))\n",
    "        \n",
    "        #Parameter\n",
    "        min_precision = 0.95\n",
    "        \n",
    "        if opt_params:\n",
    "            save_models = False\n",
    "            min_precision = 0.0\n",
    "\n",
    "        test_confidences = learner.predict_proba(test_data)\n",
    "\n",
    "        zipped = list(zip(test_confidences, test_labels))\n",
    "        if not opt_params:\n",
    "            print(\"Length of Test: \" + str(len(zipped)))\n",
    "\n",
    "        confidence_threshold = 0.5\n",
    "        first = True\n",
    "        while True:\n",
    "            #TODO: Sollte man nur die \"Wahren entfernen\"?\n",
    "            #zipped = [example for example in zipped if example[0][0] >= confidence_threshold or example[0][1] >= confidence_threshold]\n",
    "\n",
    "            \n",
    "            #(Prediction, Actual)\n",
    "            #TODO: Hier war vorher >0.5 anstatt >= confidence_threshold\n",
    "            zipped_predictions = [((example[0][1] >= confidence_threshold), example[1]) for example in zipped]\n",
    "            \n",
    "            test_labels = [example[1] for example in zipped_predictions]\n",
    "            test_labels_predicted = [example[0] for example in zipped_predictions]\n",
    "            \n",
    "            current_precision = precision_score(test_labels, test_labels_predicted)\n",
    "\n",
    "            if opt_params:\n",
    "                precisions.append(current_precision)\n",
    "                break\n",
    "            \n",
    "            print(\"For confidence \" + str(confidence_threshold) + \" reduced to \" + str(len(zipped)) + \"(\" + \\\n",
    "                  str(len([l for l in test_labels if l == True])) + \",\" + str(len([l for l in test_labels if l == False])) + \\\n",
    "                  \"). Precision: \" + str(current_precision) + \" / Recall: \" + str(recall_score(test_labels, test_labels_predicted)))\n",
    "    \n",
    "            #Not enough instances left any more\n",
    "            #TODO: Hier war vorher test_labels anstatt test_labels_predicted\n",
    "            if not valid_list(test_labels_predicted):\n",
    "                print(\"No model could be found! (Minimum number of true examples reached)\")\n",
    "                #print(\"Best Precision: \" + str(precision_score(test_labels, test_labels_predicted)))\n",
    "                break\n",
    "        \n",
    "            if current_precision >= min_precision:\n",
    "                print(\"Model found at confidence \" + str(confidence_threshold))\n",
    "                print_performance(test_labels, test_labels_predicted)\n",
    "                if save_models:\n",
    "                    save_object(learner, 'models/' + file_name[:-4]) #Strip \".csv\"\n",
    "                    save_object(confidence_threshold, 'models/' + file_name[:-4] + '_confidence')\n",
    "                    save_object(train_data.columns, 'models/' + file_name[:-4] + '_features')\n",
    "                    print('Successfully stored model, confidence and columns.')\n",
    "                break\n",
    "            \n",
    "            #Even removing on 1.0 is still not sufficient\n",
    "            if confidence_threshold >= 1.0:\n",
    "                print(\"No model could be found! (Confidence 1.0 reached)\")\n",
    "                #print(\"Best Precision: \" + str(precision_score(test_labels, test_labels_predicted)))\n",
    "                break\n",
    "\n",
    "            first = False\n",
    "            confidence_threshold = round((confidence_threshold + 0.01), 2)\n",
    "\n",
    "    if opt_params:\n",
    "        \n",
    "        #running_time = ((time.clock() - start)*1000)\n",
    "        #print(\"Time: \" + str(running_time))\n",
    "        \n",
    "        if len(precisions) > 0:\n",
    "            print(str(precisions))\n",
    "            avg_precision = np.mean(np.array(precisions))\n",
    "            if avg_precision > best_avg_precision:\n",
    "                print('New Optimum found:' + str(avg_precision))\n",
    "                print(str(params))\n",
    "                best_avg_precision = avg_precision\n",
    "\n",
    "        precisions = list()\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    print('-----')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
