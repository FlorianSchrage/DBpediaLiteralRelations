{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T12:26:44.307169Z",
     "start_time": "2018-12-14T12:26:41.627563Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import collections\n",
    "import decimal\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import time\n",
    "import dateparser\n",
    "from operator import itemgetter\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from utils.myutils import split_triple, load_object, save_object, short_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T12:26:54.222638Z",
     "start_time": "2018-12-14T12:26:54.217341Z"
    }
   },
   "outputs": [],
   "source": [
    "type_int = \"Int\"\n",
    "type_float = \"Float\"\n",
    "type_date = \"Date\"\n",
    "\n",
    "constants = (type_int, type_float, type_date)\n",
    "\n",
    "#Parameter\n",
    "improve_float_matching = True\n",
    "convert_units = True\n",
    "use_gold_standard_units = True\n",
    "only_top20 = False\n",
    "\n",
    "\n",
    "if convert_units:\n",
    "    unit_dict = load_object('unit_dict')\n",
    "    unit_conversion_dict = load_object('unit_conversion_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:50:31.824998Z",
     "start_time": "2018-11-27T14:50:31.821400Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentence_tokens_nltk(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens_extended = list()\n",
    "    offset = 0\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        offset = sentence.find(token, offset)\n",
    "        tokens_extended.append((token, i, offset))\n",
    "        offset += len(token)\n",
    "        \n",
    "    return tokens_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:50:36.063189Z",
     "start_time": "2018-11-27T14:50:36.055583Z"
    }
   },
   "outputs": [],
   "source": [
    "running_time = 0\n",
    "def get_adjacent_tokens(sentence_tokens, match_pos, local_signs=('.',',','-')):\n",
    "    #Parameter\n",
    "    number_of_neighbor_tokens = 3\n",
    "    \n",
    "    decimal_sep = local_signs[0]\n",
    "    thousands_sep = local_signs[1]\n",
    "    minus_sign = local_signs[2]\n",
    "    \n",
    "    adjacent_tokens = list()\n",
    "    token_directly_following = None\n",
    "    for token in sentence_tokens:\n",
    "        #---TRANSLATION---\n",
    "        #token[0] is the word\n",
    "        #token[1] is the index (token.i in SpaCy)\n",
    "        #token[2] is the position/offset (token.idx in SpaCy)\n",
    "\n",
    "        if match_pos > token[2]:\n",
    "            continue\n",
    "\n",
    "        #Usually both should match\n",
    "        #But mismatches can occur if the number is not en entire token itself but just part of another token\n",
    "        #In this case we take the previous token as this is the one our number-match is part of\n",
    "        if match_pos != token[2]:\n",
    "            token = sentence_tokens[token[1] - 1]\n",
    "\n",
    "        #Tokens before\n",
    "        i = token[1] - 1 #Index or i\n",
    "        number_of_neighbor_tokens_tmp = number_of_neighbor_tokens\n",
    "        while i >= 0 and i >= token[1] - number_of_neighbor_tokens_tmp:\n",
    "            if re.sub('[0-9' + thousands_sep + decimal_sep + minus_sign + ']', '', sentence_tokens[i][0]) not in string.punctuation:\n",
    "                #print(\"Token with index \" + str(i) + \" is adjacent.\")\n",
    "                adjacent_tokens.append(sentence_tokens[i][0].lower())\n",
    "            else:\n",
    "                #Skip tokens that are just punctuations or numbers\n",
    "                number_of_neighbor_tokens_tmp += 1\n",
    "            i -= 1\n",
    "\n",
    "        #Tokens after\n",
    "        i = token[1] + 1\n",
    "        number_of_neighbor_tokens_tmp = number_of_neighbor_tokens\n",
    "        while i <= (len(sentence_tokens) - 1) and i <= token[1] + number_of_neighbor_tokens_tmp:\n",
    "            if re.sub('[0-9' + thousands_sep + decimal_sep + minus_sign + ']', '', sentence_tokens[i][0]) not in string.punctuation:\n",
    "                #print(\"Token with index \" + str(i) + \" is adjacent.\")\n",
    "                adjacent_tokens.append(sentence_tokens[i][0].lower())\n",
    "                if token_directly_following is None:\n",
    "                    token_directly_following = sentence_tokens[i][0].lower()\n",
    "            else:\n",
    "                #Skip tokens that are just punctuations or numbers\n",
    "                number_of_neighbor_tokens_tmp += 1\n",
    "            i += 1\n",
    "\n",
    "        #Remove duplicates\n",
    "        adjacent_tokens = list(set(adjacent_tokens))\n",
    "\n",
    "        #For ends automatically if token is found\n",
    "        break\n",
    "    \n",
    "    if token_directly_following is None:\n",
    "        token_directly_following = '#_NONE_#'\n",
    "    \n",
    "    return (adjacent_tokens, token_directly_following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:50:50.884939Z",
     "start_time": "2018-11-27T14:50:36.717122Z"
    }
   },
   "outputs": [],
   "source": [
    "#punctuation_without_sep = '!\"#$%&\\'()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "#decimal_sep = '.'\n",
    "#thousands_sep = ','\n",
    "#minus_sign = '-'\n",
    "#language = 'en'\n",
    "#running_time = 0\n",
    "local_signs = ('.',',','-')\n",
    "date_dict = load_object('date_dict')\n",
    "\n",
    "\n",
    "def abstract_get_literals(abstract, entity=None, local_signs=('.',',','-'), constants=('Int', 'Float', 'Date'), include_dates=False, date_dict=None):\n",
    "    #global running_time\n",
    "    \n",
    "    decimal_sep, thousands_sep, minus_sign = local_signs\n",
    "    type_int, type_float, type_date = constants\n",
    "\n",
    "    punctuation_without_sep = re.sub('[' + decimal_sep + thousands_sep + minus_sign + ']','',string.punctuation)\n",
    "    \n",
    "    global_offset = 0\n",
    "    entire_list = list()\n",
    "    \n",
    "    for sentence in sent_tokenize(abstract):\n",
    "        #Remove all punctuations except for decimal_separator, thousands_separator and minus_sign\n",
    "        #translation = sentence.maketrans('', '', punctuation_without_sep)\n",
    "        #sentence_clean = sentence.translate(translation)\n",
    "        \n",
    "        sentence_clean = sentence\n",
    "        \n",
    "        #Required to find adjacent tokens\n",
    "        start = time.clock()\n",
    "        sentence_tokens = get_sentence_tokens_nltk(sentence)\n",
    "        #running_time += ((time.clock() - start)*1000)\n",
    "        \n",
    "        literals_all = list()\n",
    "        \n",
    "        numbers = re.finditer(minus_sign + '?([0-9]+[' + thousands_sep + decimal_sep + ']*)+', sentence_clean)\n",
    "        \n",
    "        integers = list()\n",
    "        floats = list()\n",
    "        dates = list()\n",
    "        \n",
    "        #Numbers (Ints and Floats) are found by Regex\n",
    "        for match in numbers:\n",
    "            #print(\"Number \" + str(match.group()) + \" starts at position \" + str(match.start()))\n",
    "            \n",
    "            #Remove dot and comma from beginning and ending\n",
    "            match_number = str(match.group()).strip(decimal_sep + thousands_sep).replace(minus_sign, '-')\n",
    "            match_pos = int(match.start())\n",
    "            \n",
    "            #Find adjacent tokens with NLTK-list (formerly SpaCy)\n",
    "            adjacent_tokens, token_directly_following = get_adjacent_tokens(sentence_tokens, match_pos, local_signs)\n",
    "            \n",
    "            #For Info-Feature: Position with respect to the entire abstract\n",
    "            this_global_offset = global_offset + match_pos\n",
    "            \n",
    "            #A number won't be an Int if it contains a decimal separator (unless if more than one -> then it is not a decimal separator)\n",
    "            if match_number.count(decimal_sep) != 1:\n",
    "                #print(\"Number \" + match_number + \" is Int\")\n",
    "                integers.append((re.sub('[' + decimal_sep + thousands_sep + ']', '', match_number), match_pos, type_int, adjacent_tokens, token_directly_following, this_global_offset))\n",
    "            \n",
    "            #A number won't be a Float if it has not exactly one decimal separator\n",
    "            if match_number.count(decimal_sep) == 1:\n",
    "                #print(\"Number \" + match_number + \" is Float\")\n",
    "                floats.append((re.sub('[' + thousands_sep + ']', '', match_number), match_pos, type_float, adjacent_tokens, token_directly_following, this_global_offset))\n",
    "        \n",
    "        #Dates are found (in advance) by SpaCy\n",
    "        if include_dates:\n",
    "            #Only take dates in this sentence\n",
    "            start_idx = global_offset\n",
    "            end_idx = global_offset + len(sentence)\n",
    "            \n",
    "            #DBpedia already has many relations 2 times (once for the entire date and once for the year only)\n",
    "            for date_info in date_dict[entity]:\n",
    "                if date_info[1] >= start_idx and date_info[1] < end_idx:\n",
    "                    match_pos = date_info[1] - global_offset\n",
    "                    adjacent_tokens, token_directly_following = get_adjacent_tokens(sentence_tokens, match_pos, local_signs)\n",
    "                    dates.append((date_info[0], match_pos, type_date, adjacent_tokens, token_directly_following, date_info[1]))\n",
    "    \n",
    "        literals_all.extend(integers)\n",
    "        literals_all.extend(floats)\n",
    "        literals_all.extend(dates)\n",
    "        \n",
    "        #Sort by Position in Sentence\n",
    "        literals_all = sorted(literals_all, key=itemgetter(1))\n",
    "        entire_list.append(literals_all)\n",
    "        \n",
    "        global_offset += len(sentence) + 1 #(might rarly make minor errors when a sentence is separated by two whitespaces)\n",
    "    \n",
    "    return entire_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:51:43.955125Z",
     "start_time": "2018-11-27T14:51:43.932386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('15.43', 6, 'Float', ['years', 'and', 'old', 'he', 'is'], 'years', 6), ('-4463', 30, 'Int', ['and', 'old', 'has', 'facebook', 'friends', 'on'], 'friends', 30)], [('1443233.44', 0, 'Float', ['people', 'live', 'in'], 'people', 58)], [('20', 6, 'Int', ['he', 'is'], '#_NONE_#', 114)]]\n"
     ]
    }
   ],
   "source": [
    "test = 'He is 15.43 years old and has -4,463 friends on Facebook. 1,443,233.44 people live in the same city as him. He is 20.'\n",
    "#--- TUPLE STRUCTURE ---\n",
    "#0: Unified Number (as String but can be casted) or Date (as Tuple containing the unified date and the type)\n",
    "#1: Position/Offset within the sentence\n",
    "#2: Literal Type (Float, Int or Date)\n",
    "#3: List of adjacent tokens within the sentence (depends on window size)\n",
    "#4: Token directly following\n",
    "#5: Position/Offset within the entire abstract\n",
    "entire_list = abstract_get_literals(test)\n",
    "print(entire_list)\n",
    "#print(element_len(entire_list))\n",
    "#fitting_list = [[t for t in sent if t[2] == type_float] for sent in entire_list]\n",
    "#print(fitting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:52:38.177341Z",
     "start_time": "2018-11-27T14:52:38.171346Z"
    }
   },
   "outputs": [],
   "source": [
    "def matched_int(fact_number, abstract_number):\n",
    "    fact_number = int(fact_number)\n",
    "    abstract_number = int(abstract_number)\n",
    "\n",
    "    if abstract_number == fact_number:\n",
    "        return \"Matched by equality\"\n",
    "    if abstract_number <= fact_number * 1.015 and abstract_number >= fact_number / 1.015:\n",
    "        return \"Matched by range\"\n",
    "    if fact_number > 1000 and abstract_number == round(fact_number / 100) * 100:\n",
    "        return \"Matched by Hundret round\"\n",
    "    if fact_number > 10000 and abstract_number == round(fact_number / 1000) * 1000:\n",
    "        return \"Matched by Thousand round\"\n",
    "    if fact_number > 100000 and abstract_number == round(fact_number / 10000) * 10000:\n",
    "        return \"Matched by 10K round\"\n",
    "    if fact_number > 1000000 and abstract_number == round(fact_number / 100000) * 100000:\n",
    "        return \"Matched by 100K round\"\n",
    "    if fact_number > 10000000 and abstract_number == round(fact_number / 1000000) * 1000000:\n",
    "        return \"Matched by Mio round\"\n",
    "    if fact_number > 100000000 and abstract_number == round(fact_number / 10000000) * 10000000:\n",
    "        return \"Matched by 10Mio round\"\n",
    "    if fact_number > 1000000000 and abstract_number == round(fact_number / 100000000) * 100000000:\n",
    "        return \"Matched by 100Mio round\"\n",
    "    if fact_number > 10000000000 and abstract_number == round(fact_number / 1000000000) * 1000000000:\n",
    "        return \"Matched by Mrd round\"\n",
    "    return \"Not matched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:53:32.304468Z",
     "start_time": "2018-11-27T14:53:32.299604Z"
    }
   },
   "outputs": [],
   "source": [
    "def matched_float(fact_number, abstract_number):    \n",
    "    #Number of decimal places\n",
    "    fact_decimals = decimal.Decimal(fact_number).as_tuple().exponent * (-1)\n",
    "    \n",
    "    fact_number = float(fact_number)\n",
    "    abstract_number = float(abstract_number)\n",
    "    \n",
    "    #if fact_number.is_integer():\n",
    "    #    return matched_int(fact_number, abstract_number)\n",
    "    \n",
    "    if abstract_number == fact_number:\n",
    "        return \"Matched by equality\"\n",
    "    if abstract_number <= fact_number * 1.015 and abstract_number >= fact_number / 1.015:\n",
    "        return \"Matched by range\"\n",
    "    #TODO: Würde man auch z.B. 1.23 auf 1.2 runden -> zu fein, oder?\n",
    "    if fact_decimals >= 3 and abstract_number == round(fact_number, 2):\n",
    "        return \"Matched by 2-Decimal round\"\n",
    "    if fact_decimals >= 4 and abstract_number == round(fact_number, 3):\n",
    "        return \"Matched by 3-Decimal round\"\n",
    "    if fact_decimals >= 5 and abstract_number == round(fact_number, 4):\n",
    "        return \"Matched by 4-Decimal round\"\n",
    "    if fact_decimals >= 6 and abstract_number == round(fact_number, 5):\n",
    "        return \"Matched by 5-Decimal round\"\n",
    "    if fact_decimals >= 7 and abstract_number == round(fact_number, 6):\n",
    "        return \"Matched by 6-Decimal round\"\n",
    "    if fact_decimals >= 8 and abstract_number == round(fact_number, 7):\n",
    "        return \"Matched by 7-Decimal round\"\n",
    "    if fact_decimals >= 9 and abstract_number == round(fact_number, 8):\n",
    "        return \"Matched by 8-Decimal round\"\n",
    "    return \"Not matched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:54:26.168066Z",
     "start_time": "2018-11-27T14:54:26.164616Z"
    }
   },
   "outputs": [],
   "source": [
    "def matched_date(fact_date, abstract_date):\n",
    "    \n",
    "    #Match entire date (YMD) against everything\n",
    "    #Match YM against YM and Y\n",
    "    #Match Year (Y) only against Year\n",
    "    if ( abstract_date[1] == 'ymd' and \\\n",
    "           ( fact_date == abstract_date[0] or fact_date == abstract_date[0][:-3] or fact_date == abstract_date[0][:-6] ) ) or \\\n",
    "       ( abstract_date[1] == 'ym' and \\\n",
    "           ( fact_date == abstract_date[0] or fact_date == abstract_date[0][:-3] ) ) or \\\n",
    "       ( abstract_date[1] == 'y' and \\\n",
    "           fact_date == abstract_date[0]):\n",
    "        return \"Matched by equality (date)\"\n",
    "    \n",
    "    return \"Not matched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:55:27.564374Z",
     "start_time": "2018-11-27T14:55:19.469894Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path_triples_filtered_sorted_by_relation = \"dbpedia/mappingbased_literals_en_filtered_sorted_by_relation.ttl\"\n",
    "\n",
    "triples_file_filtered_sorted_by_relation = open(file_path_triples_filtered_sorted_by_relation, 'r', encoding='utf-8')\n",
    "\n",
    "abstract_dict = load_object(\"abstract_dict\")\n",
    "relation_type_dict = load_object(\"relation_type_dict\")\n",
    "negative_dict = load_object('negative_dict')\n",
    "types_int = load_object(\"types_int\")\n",
    "types_float = load_object(\"types_float\")\n",
    "types_date = load_object(\"types_date\")\n",
    "\n",
    "matched_cnt = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T14:58:30.686901Z",
     "start_time": "2018-11-27T14:58:30.682467Z"
    }
   },
   "outputs": [],
   "source": [
    "relations_top20 = [\n",
    "    'http://dbpedia.org/ontology/numberOfGoals',\n",
    "    'http://dbpedia.org/ontology/numberOfMatches',\n",
    "    'http://dbpedia.org/ontology/populationTotal',\n",
    "    'http://dbpedia.org/ontology/runtime',\n",
    "    'http://dbpedia.org/ontology/elevation', #5\n",
    "    'http://dbpedia.org/ontology/squadNumber',\n",
    "    'http://dbpedia.org/ontology/height',\n",
    "    'http://dbpedia.org/ontology/areaTotal',\n",
    "    'http://dbpedia.org/ontology/weight',\n",
    "    'http://dbpedia.org/ontology/length', #10\n",
    "    'http://dbpedia.org/ontology/populationDensity',\n",
    "    'http://dbpedia.org/ontology/areaLand',\n",
    "    'http://dbpedia.org/ontology/area',\n",
    "    'http://dbpedia.org/ontology/areaWater',\n",
    "    'http://dbpedia.org/ontology/maximumElevation', #15\n",
    "    'http://dbpedia.org/ontology/minimumElevation',\n",
    "    'http://dbpedia.org/ontology/numberOfEpisodes',\n",
    "    'http://dbpedia.org/ontology/numberOfStudents',\n",
    "    'http://dbpedia.org/ontology/shipBeam',\n",
    "    'http://dbpedia.org/ontology/runwayLength' #20\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:01:30.383345Z",
     "start_time": "2018-11-27T15:01:30.377895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_cols' (list)\n"
     ]
    }
   ],
   "source": [
    "df_cols = ['IntegersInAbstract', 'IntegersInSentence',\n",
    "           'FloatsInAbstract', 'FloatsInSentence',\n",
    "           'NumbersInAbstract', 'NumbersInSentence',\n",
    "           'DatesInAbstract', 'DatesInSentence',\n",
    "           'FittingPositionInAbstract', 'FittingPositionInSentence',\n",
    "           'NumberPositionInAbstract', 'NumberPositionInSentence',\n",
    "           'PositionInAbstract', 'PositionInSentence',\n",
    "           'SentencePosition', 'StandardDeviationFactor',\n",
    "           'TokenAround', 'Type', 'Label',\n",
    "           'InfoEntity', 'InfoFactNumber',\n",
    "           'InfoAbstractNumber', 'InfoAbstractNumberConverted',\n",
    "           'InfoTokenAfter', 'InfoMatchingType', 'InfoGlobalOffset']\n",
    "%store df_cols\n",
    "\n",
    "def make_new_df(rows, columns):\n",
    "    new_df = pd.DataFrame(rows, columns=columns)\n",
    "    #TODO!!!\n",
    "    #new_df = new_df.sample(frac=0.1).reset_index(drop=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:04:30.766139Z",
     "start_time": "2018-11-27T15:04:30.763461Z"
    }
   },
   "outputs": [],
   "source": [
    "#This counts the number of base elements in a nested list (e.g a list of a 2-element list and a 3-element list is 5)\n",
    "def element_len(item):\n",
    "    if type(item) == list:\n",
    "        return sum(element_len(subitem) for subitem in item)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:54.365293Z",
     "start_time": "2018-11-27T15:07:36.120410Z"
    }
   },
   "outputs": [],
   "source": [
    "instance_types_dict = load_object(\"instance_types_dict\")\n",
    "relation_stat_dict = load_object(\"relation_stat_dict\")\n",
    "token_around_counter = collections.Counter()\n",
    "def create_record(int_list_abstract, \\\n",
    "                  float_list_abstract, \\\n",
    "                  number_list_abstract, \\\n",
    "                  date_list_abstract, \\\n",
    "                  int_list_sentence, \\\n",
    "                  float_list_sentence, \\\n",
    "                  number_list_sentence, \\\n",
    "                  date_list_sentence, \\\n",
    "                  index_abstract, \\\n",
    "                  index_sentence, \\\n",
    "                  index_sentence_fitting, \\\n",
    "                  index_sentence_number, \\\n",
    "                  flat_index, \\\n",
    "                  flat_index_fitting, \\\n",
    "                  flat_index_number, \\\n",
    "                  tokens_around, \\\n",
    "                  token_directly_following, \\\n",
    "                  found,\\\n",
    "                  entity, \\\n",
    "                  relation, \\\n",
    "                  fact_number, \\\n",
    "                  abstract_number, \\\n",
    "                  abstract_number_converted, \\\n",
    "                  matching_type, \\\n",
    "                  global_offset, \\\n",
    "                  relation_type, \\\n",
    "                  instance_types_dict, \\\n",
    "                  relation_stat_dict, \n",
    "                  track_token_around_counter):\n",
    "    \n",
    "    if track_token_around_counter:\n",
    "        global token_around_counter\n",
    "        #Store the frequencies to filter on minimum frequency later on\n",
    "        for token in tokens_around:\n",
    "            token_around_counter[token] += 1\n",
    "    \n",
    "    record_dict = dict()\n",
    "    \n",
    "    record_dict['IntegersInAbstract'] = element_len(int_list_abstract)\n",
    "    record_dict['IntegersInSentence'] = len(int_list_sentence)\n",
    "    record_dict['FloatsInAbstract'] = element_len(float_list_abstract)\n",
    "    record_dict['FloatsInSentence'] = len(float_list_sentence)\n",
    "    record_dict['NumbersInAbstract'] = element_len(number_list_abstract)\n",
    "    record_dict['NumbersInSentence'] = len(number_list_sentence)\n",
    "    record_dict['DatesInAbstract'] = element_len(date_list_abstract)\n",
    "    record_dict['DatesInSentence'] = len(date_list_sentence)\n",
    "    record_dict['FittingPositionInAbstract'] = flat_index_fitting\n",
    "    record_dict['FittingPositionInSentence'] = index_sentence_fitting\n",
    "    record_dict['NumberPositionInAbstract'] = flat_index_number\n",
    "    record_dict['NumberPositionInSentence'] = index_sentence_number\n",
    "    record_dict['PositionInAbstract'] = flat_index\n",
    "    record_dict['PositionInSentence'] = index_sentence\n",
    "    record_dict['SentencePosition'] = index_abstract\n",
    "    if relation in relation_stat_dict:\n",
    "        record_dict['StandardDeviationFactor'] = (relation_stat_dict[relation][0] - float(abstract_number)) / relation_stat_dict[relation][1] #x times stdev\n",
    "    else:\n",
    "        record_dict['StandardDeviationFactor'] = 0\n",
    "    record_dict['TokenAround'] = tokens_around\n",
    "    record_dict['Type'] = instance_types_dict[entity]\n",
    "    record_dict['Label'] = found\n",
    "    #Administrative Features - will be automatically dropped before classification\n",
    "    record_dict['InfoEntity'] = entity\n",
    "    record_dict['InfoFactNumber'] = fact_number\n",
    "    record_dict['InfoAbstractNumber'] = abstract_number\n",
    "    record_dict['InfoAbstractNumberConverted'] = abstract_number_converted\n",
    "    record_dict['InfoTokenAfter'] = token_directly_following\n",
    "    record_dict['InfoMatchingType'] = matching_type\n",
    "    record_dict['InfoGlobalOffset'] = global_offset\n",
    "    \n",
    "    #return pd.Series(record_dict)\n",
    "    return record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:12:32.551767Z",
     "start_time": "2018-11-27T15:12:32.545603Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_df(df, save_set, save_name, predefined_token_set=None):\n",
    "    print(\"Cleaning df...\")\n",
    "    \n",
    "    global token_around_counter\n",
    "    \n",
    "    token_set = set()\n",
    "    \n",
    "    #Parameters\n",
    "    min_occurrences_token_around = 10\n",
    "    top_n_only = 500\n",
    "    \n",
    "    if predefined_token_set is None:\n",
    "        if top_n_only == -1:\n",
    "            top_n_tokens = [t[0] for t in token_around_counter.most_common()]\n",
    "        else:\n",
    "            top_n_tokens = [t[0] for t in token_around_counter.most_common(top_n_only)]\n",
    "    \n",
    "    def delete_below_frequency(cell):\n",
    "        tokens_filtered = [word for word in cell if word in top_n_tokens and token_around_counter[word] >= min_occurrences_token_around]\n",
    "        \n",
    "        #Empty list not supported -> add NoneToken\n",
    "        if not tokens_filtered:\n",
    "            tokens_filtered = ['#_NONE_#']\n",
    "        \n",
    "        token_set.update(tokens_filtered)\n",
    "        return tokens_filtered\n",
    "    \n",
    "    def delete_by_predefined_token_set(cell):\n",
    "        tokens_filtered = [word for word in cell if word in predefined_token_set]\n",
    "        #Empty list not supported -> add NoneToken\n",
    "        if not tokens_filtered:\n",
    "            tokens_filtered = ['#_NONE_#']\n",
    "        return tokens_filtered\n",
    "    \n",
    "    if predefined_token_set is None:\n",
    "        df['TokenAround'] = df['TokenAround'].apply(delete_below_frequency)\n",
    "    else:\n",
    "        df['TokenAround'] = df['TokenAround'].apply(delete_by_predefined_token_set)\n",
    "    \n",
    "    if predefined_token_set is None:\n",
    "        token_around_counter = collections.Counter()\n",
    "    \n",
    "    if save_set:\n",
    "        save_object(token_set, 'data_info/' + save_name + '_tokens')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:17:10.205127Z",
     "start_time": "2018-11-27T15:17:10.202054Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_df(df, save_name):\n",
    "    print(\"Saving df...\")\n",
    "    #name = relation_name.split(\"/\")[-1]\n",
    "    try:\n",
    "        df.to_csv('data/' + save_name + '.csv',\n",
    "                  encoding = 'utf-8',\n",
    "                  sep = ',',\n",
    "                  index = False)\n",
    "        save_object(df.dtypes.to_dict(), 'data_info/' + save_name + '_dtypes')\n",
    "        print(\"Saved successfully\")\n",
    "    except PermissionError:\n",
    "        print(\"ERROR! Could not save file \" + name + \".csv due to Permission Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:22:05.263805Z",
     "start_time": "2018-11-27T15:22:05.256833Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_df_with_dummies(in_df):\n",
    "    \n",
    "    if in_df.empty:\n",
    "        return in_df\n",
    "    \n",
    "    try:\n",
    "\n",
    "        #TODO: Kann man beides vereinheitlichen?\n",
    "\n",
    "        #see https://stackoverflow.com/questions/37381862/get-dummies-for-pandas-column-containing-list\n",
    "        #Coding relies on that no record has an empty list (works for dense DataFrames but not for sparse ones!)\n",
    "        \n",
    "        print('To sparse...')\n",
    "        in_df = pd.SparseDataFrame(in_df)\n",
    "        \n",
    "        print(\"apply tuple...\")\n",
    "        in_df['Type'] = in_df['Type'].apply(tuple)\n",
    "\n",
    "        #print(in_df)\n",
    "        #print(in_df['TokenAround'].apply(pd.Series))\n",
    "\n",
    "        print(\"calc group by columns...\")\n",
    "        group_by_cols = list(in_df.columns.values)\n",
    "        group_by_cols.remove('TokenAround')\n",
    "        print(\"calc dummies...\")\n",
    "        out_df = pd.get_dummies(\n",
    "          in_df.join(pd.SparseSeries(in_df['TokenAround'].apply(pd.Series).stack().reset_index(1, drop=True),\n",
    "                            name='TokenAround1')).drop('TokenAround', axis=1).rename(columns={'TokenAround1': 'TokenAround'}),\n",
    "          columns=['TokenAround']).groupby(by=group_by_cols, as_index=False).sum()\n",
    "        \n",
    "        print(\"apply list...\")\n",
    "        out_df['Type'] = out_df['Type'].apply(list)\n",
    "\n",
    "        group_by_cols = list(out_df.columns.values)\n",
    "        group_by_cols.remove('Type')\n",
    "        out_df = pd.get_dummies(\n",
    "          out_df.join(pd.SparseSeries(out_df['Type'].apply(pd.Series).stack().reset_index(1, drop=True),\n",
    "                            name='Type1')).drop('Type', axis=1).rename(columns={'Type1': 'Type'}),\n",
    "          columns=['Type']).groupby(by=group_by_cols, as_index=False).sum()\n",
    "\n",
    "        print('To dense...')\n",
    "        out_df = out_df.to_dense()\n",
    "    except MemoryError:\n",
    "        print(\"MEMORY ERROR! Deleting Columns!\")\n",
    "        out_df = in_df.to_dense().drop(['TokenAround', 'Type'], axis=1)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:26:53.291901Z",
     "start_time": "2018-11-27T15:26:53.284778Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_units(relation, type_searched, abstract_record, convert_units=True, use_gold_standard_units=True, constants=('Int', 'Float', 'Date'), unit_dict=None, unit_conversion_dict=None, negative_dict=None):\n",
    "    \n",
    "    type_int, type_float, type_date = constants\n",
    "    \n",
    "    if convert_units and relation in unit_dict:\n",
    "        \n",
    "        try:\n",
    "            to_unit = unit_dict[relation]\n",
    "            if use_gold_standard_units:\n",
    "                factor = unit_conversion_dict[(abstract_record[4], to_unit, True)]\n",
    "            elif unit_conversion_dict[(abstract_record[4], to_unit, False)] != False:\n",
    "                factor = unit_conversion_dict[(abstract_record[4], to_unit, False)][0]\n",
    "            else:\n",
    "                raise KeyError\n",
    "\n",
    "            abstract_number_converted_float = float(abstract_record[0]) * factor\n",
    "\n",
    "            #if type_searched == type_int: -> Update to ListType\n",
    "            if type_int in type_searched:\n",
    "                if not abstract_number_converted_float.is_integer():\n",
    "                    #We wanted an int but after converting we (still) got a float\n",
    "                    return None\n",
    "                abstract_number_converted = str(int(abstract_number_converted_float))\n",
    "            #elif type_searched == type_float: -> Update to ListType\n",
    "            elif type_float in type_searched:\n",
    "                if abstract_number_converted_float.is_integer():\n",
    "                    #We wanted a float but after converting we (still) got an int\n",
    "                    return None\n",
    "                abstract_number_converted = str(abstract_number_converted_float)\n",
    "            else:\n",
    "                print('There was some error that should not occur...')\n",
    "                return None\n",
    "            #print(abstract_record[0] + ' ' + abstract_record[4] + ' converted to ' + abstract_number_converted + ' ' + to_unit + ' (fact: ' + fact_number + ')')\n",
    "        except (KeyError, TypeError):\n",
    "            abstract_number_converted = abstract_record[0]\n",
    "            #if abstract_record[2] != type_searched: -> Update to ListType\n",
    "            if abstract_record[2] not in type_searched:\n",
    "                #We did not apply unit conversion: Check hard if type still fits\n",
    "                return None\n",
    "    else:\n",
    "        abstract_number_converted = abstract_record[0]\n",
    "        #if abstract_record[2] != type_searched: -> Update to ListType\n",
    "        if abstract_record[2] not in type_searched:\n",
    "            #We did not apply unit conversion: Check hard if type still fits\n",
    "            return None\n",
    "    \n",
    "    #Allow negatives only if relation allows negatives\n",
    "    try:\n",
    "        if negative_dict[relation] == False and float(abstract_number_converted) < 0:\n",
    "            return None\n",
    "    except (KeyError, ValueError):\n",
    "        pass\n",
    "\n",
    "    return abstract_number_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T21:47:05.131967Z",
     "start_time": "2018-11-27T15:31:47.370265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now solving <http://dbpedia.org/ontology/absoluteMagnitude>\n",
      "0 entries processed\n",
      "1000 entries processed\n",
      "2000 entries processed\n",
      "3000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/acceleration>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/acquirementDate>\n",
      "5000 entries processed\n",
      "6000 entries processed\n",
      "7000 entries processed\n",
      "8000 entries processed\n",
      "9000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/activeYearsEndDate>\n",
      "14000 entries processed\n",
      "23000 entries processed\n",
      "27000 entries processed\n",
      "33000 entries processed\n",
      "35000 entries processed\n",
      "38000 entries processed\n",
      "39000 entries processed\n",
      "42000 entries processed\n",
      "47000 entries processed\n",
      "52000 entries processed\n",
      "54000 entries processed\n",
      "56000 entries processed\n",
      "59000 entries processed\n",
      "61000 entries processed\n",
      "63000 entries processed\n",
      "65000 entries processed\n",
      "68000 entries processed\n",
      "70000 entries processed\n",
      "72000 entries processed\n",
      "73000 entries processed\n",
      "76000 entries processed\n",
      "77000 entries processed\n",
      "79000 entries processed\n",
      "90000 entries processed\n",
      "91000 entries processed\n",
      "93000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/activeYearsEndYear>\n",
      "94000 entries processed\n",
      "95000 entries processed\n",
      "96000 entries processed\n",
      "97000 entries processed\n",
      "98000 entries processed\n",
      "99000 entries processed\n",
      "100000 entries processed\n",
      "101000 entries processed\n",
      "102000 entries processed\n",
      "103000 entries processed\n",
      "104000 entries processed\n",
      "105000 entries processed\n",
      "107000 entries processed\n",
      "108000 entries processed\n",
      "109000 entries processed\n",
      "110000 entries processed\n",
      "112000 entries processed\n",
      "113000 entries processed\n",
      "115000 entries processed\n",
      "116000 entries processed\n",
      "119000 entries processed\n",
      "120000 entries processed\n",
      "124000 entries processed\n",
      "125000 entries processed\n",
      "127000 entries processed\n",
      "128000 entries processed\n",
      "129000 entries processed\n",
      "130000 entries processed\n",
      "131000 entries processed\n",
      "134000 entries processed\n",
      "138000 entries processed\n",
      "140000 entries processed\n",
      "141000 entries processed\n",
      "142000 entries processed\n",
      "143000 entries processed\n",
      "145000 entries processed\n",
      "146000 entries processed\n",
      "147000 entries processed\n",
      "150000 entries processed\n",
      "151000 entries processed\n",
      "154000 entries processed\n",
      "155000 entries processed\n",
      "156000 entries processed\n",
      "160000 entries processed\n",
      "161000 entries processed\n",
      "162000 entries processed\n",
      "163000 entries processed\n",
      "165000 entries processed\n",
      "166000 entries processed\n",
      "167000 entries processed\n",
      "168000 entries processed\n",
      "169000 entries processed\n",
      "172000 entries processed\n",
      "177000 entries processed\n",
      "181000 entries processed\n",
      "182000 entries processed\n",
      "183000 entries processed\n",
      "185000 entries processed\n",
      "186000 entries processed\n",
      "188000 entries processed\n",
      "189000 entries processed\n",
      "190000 entries processed\n",
      "191000 entries processed\n",
      "192000 entries processed\n",
      "194000 entries processed\n",
      "195000 entries processed\n",
      "196000 entries processed\n",
      "198000 entries processed\n",
      "199000 entries processed\n",
      "201000 entries processed\n",
      "202000 entries processed\n",
      "204000 entries processed\n",
      "205000 entries processed\n",
      "206000 entries processed\n",
      "208000 entries processed\n",
      "209000 entries processed\n",
      "210000 entries processed\n",
      "211000 entries processed\n",
      "212000 entries processed\n",
      "213000 entries processed\n",
      "215000 entries processed\n",
      "216000 entries processed\n",
      "218000 entries processed\n",
      "223000 entries processed\n",
      "225000 entries processed\n",
      "227000 entries processed\n",
      "230000 entries processed\n",
      "232000 entries processed\n",
      "233000 entries processed\n",
      "235000 entries processed\n",
      "238000 entries processed\n",
      "239000 entries processed\n",
      "240000 entries processed\n",
      "242000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/activeYearsStartDate>\n",
      "250000 entries processed\n",
      "251000 entries processed\n",
      "252000 entries processed\n",
      "254000 entries processed\n",
      "256000 entries processed\n",
      "257000 entries processed\n",
      "259000 entries processed\n",
      "260000 entries processed\n",
      "262000 entries processed\n",
      "266000 entries processed\n",
      "271000 entries processed\n",
      "273000 entries processed\n",
      "274000 entries processed\n",
      "277000 entries processed\n",
      "278000 entries processed\n",
      "281000 entries processed\n",
      "286000 entries processed\n",
      "295000 entries processed\n",
      "297000 entries processed\n",
      "298000 entries processed\n",
      "299000 entries processed\n",
      "302000 entries processed\n",
      "304000 entries processed\n",
      "306000 entries processed\n",
      "308000 entries processed\n",
      "311000 entries processed\n",
      "314000 entries processed\n",
      "315000 entries processed\n",
      "317000 entries processed\n",
      "319000 entries processed\n",
      "322000 entries processed\n",
      "323000 entries processed\n",
      "324000 entries processed\n",
      "341000 entries processed\n",
      "342000 entries processed\n",
      "346000 entries processed\n",
      "347000 entries processed\n",
      "348000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/activeYearsStartYear>\n",
      "349000 entries processed\n",
      "350000 entries processed\n",
      "351000 entries processed\n",
      "352000 entries processed\n",
      "353000 entries processed\n",
      "354000 entries processed\n",
      "355000 entries processed\n",
      "356000 entries processed\n",
      "357000 entries processed\n",
      "358000 entries processed\n",
      "360000 entries processed\n",
      "361000 entries processed\n",
      "362000 entries processed\n",
      "363000 entries processed\n",
      "364000 entries processed\n",
      "366000 entries processed\n",
      "367000 entries processed\n",
      "368000 entries processed\n",
      "371000 entries processed\n",
      "372000 entries processed\n",
      "373000 entries processed\n",
      "374000 entries processed\n",
      "375000 entries processed\n",
      "377000 entries processed\n",
      "378000 entries processed\n",
      "379000 entries processed\n",
      "381000 entries processed\n",
      "382000 entries processed\n",
      "383000 entries processed\n",
      "386000 entries processed\n",
      "387000 entries processed\n",
      "388000 entries processed\n",
      "390000 entries processed\n",
      "391000 entries processed\n",
      "395000 entries processed\n",
      "396000 entries processed\n",
      "398000 entries processed\n",
      "399000 entries processed\n",
      "400000 entries processed\n",
      "401000 entries processed\n",
      "402000 entries processed\n",
      "403000 entries processed\n",
      "405000 entries processed\n",
      "406000 entries processed\n",
      "407000 entries processed\n",
      "408000 entries processed\n",
      "409000 entries processed\n",
      "410000 entries processed\n",
      "411000 entries processed\n",
      "413000 entries processed\n",
      "414000 entries processed\n",
      "416000 entries processed\n",
      "418000 entries processed\n",
      "419000 entries processed\n",
      "420000 entries processed\n",
      "421000 entries processed\n",
      "422000 entries processed\n",
      "423000 entries processed\n",
      "424000 entries processed\n",
      "425000 entries processed\n",
      "426000 entries processed\n",
      "427000 entries processed\n",
      "428000 entries processed\n",
      "431000 entries processed\n",
      "432000 entries processed\n",
      "433000 entries processed\n",
      "434000 entries processed\n",
      "435000 entries processed\n",
      "436000 entries processed\n",
      "437000 entries processed\n",
      "438000 entries processed\n",
      "439000 entries processed\n",
      "440000 entries processed\n",
      "441000 entries processed\n",
      "442000 entries processed\n",
      "443000 entries processed\n",
      "444000 entries processed\n",
      "446000 entries processed\n",
      "447000 entries processed\n",
      "448000 entries processed\n",
      "450000 entries processed\n",
      "451000 entries processed\n",
      "452000 entries processed\n",
      "455000 entries processed\n",
      "456000 entries processed\n",
      "457000 entries processed\n",
      "458000 entries processed\n",
      "459000 entries processed\n",
      "460000 entries processed\n",
      "461000 entries processed\n",
      "462000 entries processed\n",
      "463000 entries processed\n",
      "464000 entries processed\n",
      "465000 entries processed\n",
      "466000 entries processed\n",
      "467000 entries processed\n",
      "468000 entries processed\n",
      "469000 entries processed\n",
      "470000 entries processed\n",
      "471000 entries processed\n",
      "474000 entries processed\n",
      "475000 entries processed\n",
      "476000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477000 entries processed\n",
      "479000 entries processed\n",
      "480000 entries processed\n",
      "481000 entries processed\n",
      "482000 entries processed\n",
      "483000 entries processed\n",
      "484000 entries processed\n",
      "485000 entries processed\n",
      "487000 entries processed\n",
      "488000 entries processed\n",
      "489000 entries processed\n",
      "490000 entries processed\n",
      "491000 entries processed\n",
      "492000 entries processed\n",
      "493000 entries processed\n",
      "494000 entries processed\n",
      "495000 entries processed\n",
      "497000 entries processed\n",
      "498000 entries processed\n",
      "499000 entries processed\n",
      "500000 entries processed\n",
      "501000 entries processed\n",
      "502000 entries processed\n",
      "503000 entries processed\n",
      "504000 entries processed\n",
      "505000 entries processed\n",
      "506000 entries processed\n",
      "507000 entries processed\n",
      "508000 entries processed\n",
      "509000 entries processed\n",
      "510000 entries processed\n",
      "511000 entries processed\n",
      "512000 entries processed\n",
      "513000 entries processed\n",
      "514000 entries processed\n",
      "516000 entries processed\n",
      "517000 entries processed\n",
      "518000 entries processed\n",
      "519000 entries processed\n",
      "520000 entries processed\n",
      "521000 entries processed\n",
      "522000 entries processed\n",
      "523000 entries processed\n",
      "525000 entries processed\n",
      "526000 entries processed\n",
      "528000 entries processed\n",
      "529000 entries processed\n",
      "530000 entries processed\n",
      "535000 entries processed\n",
      "537000 entries processed\n",
      "538000 entries processed\n",
      "539000 entries processed\n",
      "541000 entries processed\n",
      "542000 entries processed\n",
      "544000 entries processed\n",
      "545000 entries processed\n",
      "546000 entries processed\n",
      "547000 entries processed\n",
      "548000 entries processed\n",
      "550000 entries processed\n",
      "551000 entries processed\n",
      "552000 entries processed\n",
      "553000 entries processed\n",
      "554000 entries processed\n",
      "555000 entries processed\n",
      "556000 entries processed\n",
      "557000 entries processed\n",
      "558000 entries processed\n",
      "559000 entries processed\n",
      "561000 entries processed\n",
      "563000 entries processed\n",
      "565000 entries processed\n",
      "567000 entries processed\n",
      "568000 entries processed\n",
      "569000 entries processed\n",
      "570000 entries processed\n",
      "571000 entries processed\n",
      "572000 entries processed\n",
      "573000 entries processed\n",
      "574000 entries processed\n",
      "575000 entries processed\n",
      "577000 entries processed\n",
      "578000 entries processed\n",
      "580000 entries processed\n",
      "581000 entries processed\n",
      "582000 entries processed\n",
      "583000 entries processed\n",
      "584000 entries processed\n",
      "585000 entries processed\n",
      "586000 entries processed\n",
      "588000 entries processed\n",
      "589000 entries processed\n",
      "590000 entries processed\n",
      "591000 entries processed\n",
      "592000 entries processed\n",
      "593000 entries processed\n",
      "595000 entries processed\n",
      "597000 entries processed\n",
      "598000 entries processed\n",
      "600000 entries processed\n",
      "601000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/added>\n",
      "604000 entries processed\n",
      "605000 entries processed\n",
      "606000 entries processed\n",
      "607000 entries processed\n",
      "608000 entries processed\n",
      "609000 entries processed\n",
      "610000 entries processed\n",
      "611000 entries processed\n",
      "612000 entries processed\n",
      "613000 entries processed\n",
      "614000 entries processed\n",
      "615000 entries processed\n",
      "616000 entries processed\n",
      "617000 entries processed\n",
      "618000 entries processed\n",
      "619000 entries processed\n",
      "620000 entries processed\n",
      "621000 entries processed\n",
      "622000 entries processed\n",
      "623000 entries processed\n",
      "624000 entries processed\n",
      "625000 entries processed\n",
      "626000 entries processed\n",
      "627000 entries processed\n",
      "628000 entries processed\n",
      "629000 entries processed\n",
      "630000 entries processed\n",
      "631000 entries processed\n",
      "632000 entries processed\n",
      "633000 entries processed\n",
      "634000 entries processed\n",
      "635000 entries processed\n",
      "636000 entries processed\n",
      "637000 entries processed\n",
      "638000 entries processed\n",
      "639000 entries processed\n",
      "640000 entries processed\n",
      "641000 entries processed\n",
      "642000 entries processed\n",
      "643000 entries processed\n",
      "644000 entries processed\n",
      "645000 entries processed\n",
      "646000 entries processed\n",
      "647000 entries processed\n",
      "648000 entries processed\n",
      "649000 entries processed\n",
      "650000 entries processed\n",
      "651000 entries processed\n",
      "652000 entries processed\n",
      "653000 entries processed\n",
      "654000 entries processed\n",
      "655000 entries processed\n",
      "656000 entries processed\n",
      "657000 entries processed\n",
      "658000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "702000 entries processed\n",
      "703000 entries processed\n",
      "704000 entries processed\n",
      "705000 entries processed\n",
      "706000 entries processed\n",
      "707000 entries processed\n",
      "708000 entries processed\n",
      "709000 entries processed\n",
      "710000 entries processed\n",
      "711000 entries processed\n",
      "712000 entries processed\n",
      "713000 entries processed\n",
      "714000 entries processed\n",
      "715000 entries processed\n",
      "716000 entries processed\n",
      "717000 entries processed\n",
      "718000 entries processed\n",
      "719000 entries processed\n",
      "720000 entries processed\n",
      "722000 entries processed\n",
      "723000 entries processed\n",
      "725000 entries processed\n",
      "726000 entries processed\n",
      "727000 entries processed\n",
      "728000 entries processed\n",
      "729000 entries processed\n",
      "730000 entries processed\n",
      "731000 entries processed\n",
      "732000 entries processed\n",
      "733000 entries processed\n",
      "734000 entries processed\n",
      "735000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaLand>\n",
      "736000 entries processed\n",
      "737000 entries processed\n",
      "738000 entries processed\n",
      "739000 entries processed\n",
      "740000 entries processed\n",
      "741000 entries processed\n",
      "742000 entries processed\n",
      "743000 entries processed\n",
      "744000 entries processed\n",
      "745000 entries processed\n",
      "746000 entries processed\n",
      "747000 entries processed\n",
      "748000 entries processed\n",
      "749000 entries processed\n",
      "750000 entries processed\n",
      "751000 entries processed\n",
      "752000 entries processed\n",
      "753000 entries processed\n",
      "754000 entries processed\n",
      "755000 entries processed\n",
      "756000 entries processed\n",
      "757000 entries processed\n",
      "758000 entries processed\n",
      "759000 entries processed\n",
      "760000 entries processed\n",
      "761000 entries processed\n",
      "762000 entries processed\n",
      "763000 entries processed\n",
      "764000 entries processed\n",
      "765000 entries processed\n",
      "766000 entries processed\n",
      "767000 entries processed\n",
      "768000 entries processed\n",
      "769000 entries processed\n",
      "770000 entries processed\n",
      "771000 entries processed\n",
      "772000 entries processed\n",
      "773000 entries processed\n",
      "774000 entries processed\n",
      "775000 entries processed\n",
      "776000 entries processed\n",
      "777000 entries processed\n",
      "778000 entries processed\n",
      "779000 entries processed\n",
      "780000 entries processed\n",
      "781000 entries processed\n",
      "782000 entries processed\n",
      "783000 entries processed\n",
      "784000 entries processed\n",
      "785000 entries processed\n",
      "786000 entries processed\n",
      "787000 entries processed\n",
      "788000 entries processed\n",
      "789000 entries processed\n",
      "790000 entries processed\n",
      "791000 entries processed\n",
      "792000 entries processed\n",
      "793000 entries processed\n",
      "794000 entries processed\n",
      "795000 entries processed\n",
      "796000 entries processed\n",
      "797000 entries processed\n",
      "798000 entries processed\n",
      "799000 entries processed\n",
      "800000 entries processed\n",
      "801000 entries processed\n",
      "802000 entries processed\n",
      "803000 entries processed\n",
      "804000 entries processed\n",
      "805000 entries processed\n",
      "806000 entries processed\n",
      "807000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaMetro>\n",
      "808000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaOfCatchment>\n",
      "809000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaRural>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaTotal>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810000 entries processed\n",
      "811000 entries processed\n",
      "812000 entries processed\n",
      "813000 entries processed\n",
      "814000 entries processed\n",
      "815000 entries processed\n",
      "816000 entries processed\n",
      "817000 entries processed\n",
      "818000 entries processed\n",
      "819000 entries processed\n",
      "820000 entries processed\n",
      "821000 entries processed\n",
      "822000 entries processed\n",
      "823000 entries processed\n",
      "824000 entries processed\n",
      "825000 entries processed\n",
      "826000 entries processed\n",
      "827000 entries processed\n",
      "828000 entries processed\n",
      "829000 entries processed\n",
      "830000 entries processed\n",
      "831000 entries processed\n",
      "832000 entries processed\n",
      "833000 entries processed\n",
      "834000 entries processed\n",
      "835000 entries processed\n",
      "836000 entries processed\n",
      "837000 entries processed\n",
      "838000 entries processed\n",
      "839000 entries processed\n",
      "840000 entries processed\n",
      "841000 entries processed\n",
      "842000 entries processed\n",
      "843000 entries processed\n",
      "844000 entries processed\n",
      "845000 entries processed\n",
      "846000 entries processed\n",
      "847000 entries processed\n",
      "848000 entries processed\n",
      "849000 entries processed\n",
      "850000 entries processed\n",
      "851000 entries processed\n",
      "852000 entries processed\n",
      "853000 entries processed\n",
      "854000 entries processed\n",
      "855000 entries processed\n",
      "856000 entries processed\n",
      "857000 entries processed\n",
      "858000 entries processed\n",
      "859000 entries processed\n",
      "860000 entries processed\n",
      "861000 entries processed\n",
      "862000 entries processed\n",
      "863000 entries processed\n",
      "864000 entries processed\n",
      "865000 entries processed\n",
      "866000 entries processed\n",
      "867000 entries processed\n",
      "868000 entries processed\n",
      "869000 entries processed\n",
      "870000 entries processed\n",
      "871000 entries processed\n",
      "872000 entries processed\n",
      "873000 entries processed\n",
      "874000 entries processed\n",
      "875000 entries processed\n",
      "876000 entries processed\n",
      "877000 entries processed\n",
      "878000 entries processed\n",
      "879000 entries processed\n",
      "880000 entries processed\n",
      "881000 entries processed\n",
      "882000 entries processed\n",
      "883000 entries processed\n",
      "884000 entries processed\n",
      "885000 entries processed\n",
      "886000 entries processed\n",
      "887000 entries processed\n",
      "888000 entries processed\n",
      "889000 entries processed\n",
      "890000 entries processed\n",
      "891000 entries processed\n",
      "892000 entries processed\n",
      "893000 entries processed\n",
      "894000 entries processed\n",
      "895000 entries processed\n",
      "896000 entries processed\n",
      "897000 entries processed\n",
      "898000 entries processed\n",
      "899000 entries processed\n",
      "900000 entries processed\n",
      "901000 entries processed\n",
      "902000 entries processed\n",
      "903000 entries processed\n",
      "904000 entries processed\n",
      "905000 entries processed\n",
      "906000 entries processed\n",
      "907000 entries processed\n",
      "908000 entries processed\n",
      "909000 entries processed\n",
      "910000 entries processed\n",
      "911000 entries processed\n",
      "912000 entries processed\n",
      "913000 entries processed\n",
      "914000 entries processed\n",
      "915000 entries processed\n",
      "916000 entries processed\n",
      "917000 entries processed\n",
      "918000 entries processed\n",
      "919000 entries processed\n",
      "920000 entries processed\n",
      "921000 entries processed\n",
      "922000 entries processed\n",
      "923000 entries processed\n",
      "924000 entries processed\n",
      "925000 entries processed\n",
      "926000 entries processed\n",
      "927000 entries processed\n",
      "928000 entries processed\n",
      "929000 entries processed\n",
      "930000 entries processed\n",
      "931000 entries processed\n",
      "932000 entries processed\n",
      "933000 entries processed\n",
      "934000 entries processed\n",
      "935000 entries processed\n",
      "936000 entries processed\n",
      "937000 entries processed\n",
      "938000 entries processed\n",
      "939000 entries processed\n",
      "940000 entries processed\n",
      "941000 entries processed\n",
      "942000 entries processed\n",
      "943000 entries processed\n",
      "944000 entries processed\n",
      "945000 entries processed\n",
      "946000 entries processed\n",
      "947000 entries processed\n",
      "948000 entries processed\n",
      "949000 entries processed\n",
      "950000 entries processed\n",
      "951000 entries processed\n",
      "952000 entries processed\n",
      "953000 entries processed\n",
      "954000 entries processed\n",
      "955000 entries processed\n",
      "956000 entries processed\n",
      "957000 entries processed\n",
      "958000 entries processed\n",
      "959000 entries processed\n",
      "960000 entries processed\n",
      "961000 entries processed\n",
      "962000 entries processed\n",
      "963000 entries processed\n",
      "964000 entries processed\n",
      "965000 entries processed\n",
      "966000 entries processed\n",
      "967000 entries processed\n",
      "968000 entries processed\n",
      "969000 entries processed\n",
      "970000 entries processed\n",
      "971000 entries processed\n",
      "972000 entries processed\n",
      "973000 entries processed\n",
      "974000 entries processed\n",
      "976000 entries processed\n",
      "977000 entries processed\n",
      "978000 entries processed\n",
      "979000 entries processed\n",
      "980000 entries processed\n",
      "981000 entries processed\n",
      "982000 entries processed\n",
      "983000 entries processed\n",
      "984000 entries processed\n",
      "985000 entries processed\n",
      "986000 entries processed\n",
      "987000 entries processed\n",
      "988000 entries processed\n",
      "989000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaUrban>\n",
      "990000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/areaWater>\n",
      "991000 entries processed\n",
      "992000 entries processed\n",
      "993000 entries processed\n",
      "994000 entries processed\n",
      "995000 entries processed\n",
      "996000 entries processed\n",
      "997000 entries processed\n",
      "998000 entries processed\n",
      "999000 entries processed\n",
      "1000000 entries processed\n",
      "1001000 entries processed\n",
      "1002000 entries processed\n",
      "1003000 entries processed\n",
      "1004000 entries processed\n",
      "1005000 entries processed\n",
      "1006000 entries processed\n",
      "1007000 entries processed\n",
      "1008000 entries processed\n",
      "1009000 entries processed\n",
      "1010000 entries processed\n",
      "1011000 entries processed\n",
      "1012000 entries processed\n",
      "1013000 entries processed\n",
      "1014000 entries processed\n",
      "1015000 entries processed\n",
      "1016000 entries processed\n",
      "1017000 entries processed\n",
      "1018000 entries processed\n",
      "1019000 entries processed\n",
      "1020000 entries processed\n",
      "1021000 entries processed\n",
      "1022000 entries processed\n",
      "1023000 entries processed\n",
      "1024000 entries processed\n",
      "1025000 entries processed\n",
      "1026000 entries processed\n",
      "1027000 entries processed\n",
      "1028000 entries processed\n",
      "1029000 entries processed\n",
      "1030000 entries processed\n",
      "1031000 entries processed\n",
      "1032000 entries processed\n",
      "1033000 entries processed\n",
      "1034000 entries processed\n",
      "1035000 entries processed\n",
      "1036000 entries processed\n",
      "1037000 entries processed\n",
      "1038000 entries processed\n",
      "1039000 entries processed\n",
      "1040000 entries processed\n",
      "1041000 entries processed\n",
      "1042000 entries processed\n",
      "1043000 entries processed\n",
      "1044000 entries processed\n",
      "1045000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/argueDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/assetUnderManagement>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/assets>\n",
      "1046000 entries processed\n",
      "1047000 entries processed\n",
      "1048000 entries processed\n",
      "1049000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/averageAnnualGeneration>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/averageClassSize>\n",
      "1051000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/averageDepth>\n",
      "1052000 entries processed\n",
      "1053000 entries processed\n",
      "1054000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/averageSpeed>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/barPassRate>\n",
      "1055000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/beatifiedDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/bedCount>\n",
      "1056000 entries processed\n",
      "1057000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/bioavailability>\n",
      "1058000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/birthDate>\n",
      "1059000 entries processed\n",
      "1060000 entries processed\n",
      "1061000 entries processed\n",
      "1062000 entries processed\n",
      "1063000 entries processed\n",
      "1064000 entries processed\n",
      "1065000 entries processed\n",
      "1066000 entries processed\n",
      "1067000 entries processed\n",
      "1068000 entries processed\n",
      "1069000 entries processed\n",
      "1070000 entries processed\n",
      "1071000 entries processed\n",
      "1072000 entries processed\n",
      "1073000 entries processed\n",
      "1074000 entries processed\n",
      "1075000 entries processed\n",
      "1076000 entries processed\n",
      "1077000 entries processed\n",
      "1078000 entries processed\n",
      "1079000 entries processed\n",
      "1080000 entries processed\n",
      "1081000 entries processed\n",
      "1082000 entries processed\n",
      "1083000 entries processed\n",
      "1084000 entries processed\n",
      "1085000 entries processed\n",
      "1086000 entries processed\n",
      "1087000 entries processed\n",
      "1088000 entries processed\n",
      "1089000 entries processed\n",
      "1090000 entries processed\n",
      "1091000 entries processed\n",
      "1092000 entries processed\n",
      "1093000 entries processed\n",
      "1094000 entries processed\n",
      "1095000 entries processed\n",
      "1096000 entries processed\n",
      "1097000 entries processed\n",
      "1098000 entries processed\n",
      "1099000 entries processed\n",
      "1100000 entries processed\n",
      "1101000 entries processed\n",
      "1102000 entries processed\n",
      "1103000 entries processed\n",
      "1104000 entries processed\n",
      "1105000 entries processed\n",
      "1106000 entries processed\n",
      "1107000 entries processed\n",
      "1108000 entries processed\n",
      "1109000 entries processed\n",
      "1110000 entries processed\n",
      "1111000 entries processed\n",
      "1112000 entries processed\n",
      "1113000 entries processed\n",
      "1114000 entries processed\n",
      "1115000 entries processed\n",
      "1116000 entries processed\n",
      "1117000 entries processed\n",
      "1118000 entries processed\n",
      "1119000 entries processed\n",
      "1120000 entries processed\n",
      "1121000 entries processed\n",
      "1122000 entries processed\n",
      "1123000 entries processed\n",
      "1124000 entries processed\n",
      "1125000 entries processed\n",
      "1126000 entries processed\n",
      "1127000 entries processed\n",
      "1128000 entries processed\n",
      "1129000 entries processed\n",
      "1130000 entries processed\n",
      "1131000 entries processed\n",
      "1132000 entries processed\n",
      "1133000 entries processed\n",
      "1134000 entries processed\n",
      "1135000 entries processed\n",
      "1136000 entries processed\n",
      "1137000 entries processed\n",
      "1138000 entries processed\n",
      "1139000 entries processed\n",
      "1140000 entries processed\n",
      "1141000 entries processed\n",
      "1142000 entries processed\n",
      "1143000 entries processed\n",
      "1144000 entries processed\n",
      "1145000 entries processed\n",
      "1146000 entries processed\n",
      "1147000 entries processed\n",
      "1148000 entries processed\n",
      "1149000 entries processed\n",
      "1150000 entries processed\n",
      "1151000 entries processed\n",
      "1152000 entries processed\n",
      "1153000 entries processed\n",
      "1154000 entries processed\n",
      "1155000 entries processed\n",
      "1156000 entries processed\n",
      "1157000 entries processed\n",
      "1158000 entries processed\n",
      "1159000 entries processed\n",
      "1160000 entries processed\n",
      "1161000 entries processed\n",
      "1162000 entries processed\n",
      "1163000 entries processed\n",
      "1164000 entries processed\n",
      "1165000 entries processed\n",
      "1166000 entries processed\n",
      "1167000 entries processed\n",
      "1168000 entries processed\n",
      "1169000 entries processed\n",
      "1170000 entries processed\n",
      "1171000 entries processed\n",
      "1172000 entries processed\n",
      "1173000 entries processed\n",
      "1174000 entries processed\n",
      "1175000 entries processed\n",
      "1176000 entries processed\n",
      "1177000 entries processed\n",
      "1178000 entries processed\n",
      "1179000 entries processed\n",
      "1180000 entries processed\n",
      "1181000 entries processed\n",
      "1182000 entries processed\n",
      "1183000 entries processed\n",
      "1184000 entries processed\n",
      "1185000 entries processed\n",
      "1186000 entries processed\n",
      "1187000 entries processed\n",
      "1188000 entries processed\n",
      "1189000 entries processed\n",
      "1190000 entries processed\n",
      "1191000 entries processed\n",
      "1192000 entries processed\n",
      "1193000 entries processed\n",
      "1194000 entries processed\n",
      "1195000 entries processed\n",
      "1196000 entries processed\n",
      "1197000 entries processed\n",
      "1198000 entries processed\n",
      "1199000 entries processed\n",
      "1200000 entries processed\n",
      "1201000 entries processed\n",
      "1202000 entries processed\n",
      "1203000 entries processed\n",
      "1204000 entries processed\n",
      "1205000 entries processed\n",
      "1206000 entries processed\n",
      "1207000 entries processed\n",
      "1208000 entries processed\n",
      "1209000 entries processed\n",
      "1210000 entries processed\n",
      "1211000 entries processed\n",
      "1212000 entries processed\n",
      "1213000 entries processed\n",
      "1214000 entries processed\n",
      "1215000 entries processed\n",
      "1216000 entries processed\n",
      "1217000 entries processed\n",
      "1218000 entries processed\n",
      "1219000 entries processed\n",
      "1220000 entries processed\n",
      "1221000 entries processed\n",
      "1222000 entries processed\n",
      "1223000 entries processed\n",
      "1224000 entries processed\n",
      "1225000 entries processed\n",
      "1226000 entries processed\n",
      "1227000 entries processed\n",
      "1228000 entries processed\n",
      "1229000 entries processed\n",
      "1230000 entries processed\n",
      "1231000 entries processed\n",
      "1232000 entries processed\n",
      "1233000 entries processed\n",
      "1234000 entries processed\n",
      "1235000 entries processed\n",
      "1236000 entries processed\n",
      "1237000 entries processed\n",
      "1238000 entries processed\n",
      "1239000 entries processed\n",
      "1240000 entries processed\n",
      "1241000 entries processed\n",
      "1242000 entries processed\n",
      "1243000 entries processed\n",
      "1244000 entries processed\n",
      "1245000 entries processed\n",
      "1246000 entries processed\n",
      "1247000 entries processed\n",
      "1248000 entries processed\n",
      "1249000 entries processed\n",
      "1250000 entries processed\n",
      "1251000 entries processed\n",
      "1252000 entries processed\n",
      "1253000 entries processed\n",
      "1254000 entries processed\n",
      "1255000 entries processed\n",
      "1256000 entries processed\n",
      "1257000 entries processed\n",
      "1258000 entries processed\n",
      "1259000 entries processed\n",
      "1260000 entries processed\n",
      "1261000 entries processed\n",
      "1262000 entries processed\n",
      "1263000 entries processed\n",
      "1264000 entries processed\n",
      "1265000 entries processed\n",
      "1266000 entries processed\n",
      "1267000 entries processed\n",
      "1268000 entries processed\n",
      "1269000 entries processed\n",
      "1270000 entries processed\n",
      "1271000 entries processed\n",
      "1272000 entries processed\n",
      "1273000 entries processed\n",
      "1274000 entries processed\n",
      "1275000 entries processed\n",
      "1276000 entries processed\n",
      "1277000 entries processed\n",
      "1278000 entries processed\n",
      "1279000 entries processed\n",
      "1280000 entries processed\n",
      "1281000 entries processed\n",
      "1282000 entries processed\n",
      "1283000 entries processed\n",
      "1284000 entries processed\n",
      "1285000 entries processed\n",
      "1286000 entries processed\n",
      "1287000 entries processed\n",
      "1288000 entries processed\n",
      "1289000 entries processed\n",
      "1290000 entries processed\n",
      "1291000 entries processed\n",
      "1292000 entries processed\n",
      "1293000 entries processed\n",
      "1294000 entries processed\n",
      "1295000 entries processed\n",
      "1296000 entries processed\n",
      "1297000 entries processed\n",
      "1298000 entries processed\n",
      "1299000 entries processed\n",
      "1300000 entries processed\n",
      "1301000 entries processed\n",
      "1302000 entries processed\n",
      "1303000 entries processed\n",
      "1304000 entries processed\n",
      "1305000 entries processed\n",
      "1306000 entries processed\n",
      "1307000 entries processed\n",
      "1308000 entries processed\n",
      "1309000 entries processed\n",
      "1310000 entries processed\n",
      "1311000 entries processed\n",
      "1312000 entries processed\n",
      "1313000 entries processed\n",
      "1314000 entries processed\n",
      "1315000 entries processed\n",
      "1316000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317000 entries processed\n",
      "1318000 entries processed\n",
      "1319000 entries processed\n",
      "1320000 entries processed\n",
      "1321000 entries processed\n",
      "1322000 entries processed\n",
      "1323000 entries processed\n",
      "1324000 entries processed\n",
      "1325000 entries processed\n",
      "1326000 entries processed\n",
      "1327000 entries processed\n",
      "1328000 entries processed\n",
      "1329000 entries processed\n",
      "1330000 entries processed\n",
      "1331000 entries processed\n",
      "1332000 entries processed\n",
      "1333000 entries processed\n",
      "1334000 entries processed\n",
      "1335000 entries processed\n",
      "1336000 entries processed\n",
      "1337000 entries processed\n",
      "1338000 entries processed\n",
      "1339000 entries processed\n",
      "1340000 entries processed\n",
      "1341000 entries processed\n",
      "1342000 entries processed\n",
      "1343000 entries processed\n",
      "1344000 entries processed\n",
      "1345000 entries processed\n",
      "1346000 entries processed\n",
      "1347000 entries processed\n",
      "1348000 entries processed\n",
      "1349000 entries processed\n",
      "1350000 entries processed\n",
      "1351000 entries processed\n",
      "1352000 entries processed\n",
      "1353000 entries processed\n",
      "1354000 entries processed\n",
      "1355000 entries processed\n",
      "1356000 entries processed\n",
      "1357000 entries processed\n",
      "1358000 entries processed\n",
      "1359000 entries processed\n",
      "1360000 entries processed\n",
      "1361000 entries processed\n",
      "1362000 entries processed\n",
      "1363000 entries processed\n",
      "1364000 entries processed\n",
      "1365000 entries processed\n",
      "1366000 entries processed\n",
      "1367000 entries processed\n",
      "1368000 entries processed\n",
      "1369000 entries processed\n",
      "1370000 entries processed\n",
      "1371000 entries processed\n",
      "1372000 entries processed\n",
      "1373000 entries processed\n",
      "1374000 entries processed\n",
      "1375000 entries processed\n",
      "1376000 entries processed\n",
      "1377000 entries processed\n",
      "1378000 entries processed\n",
      "1379000 entries processed\n",
      "1380000 entries processed\n",
      "1381000 entries processed\n",
      "1382000 entries processed\n",
      "1383000 entries processed\n",
      "1384000 entries processed\n",
      "1385000 entries processed\n",
      "1386000 entries processed\n",
      "1387000 entries processed\n",
      "1388000 entries processed\n",
      "1389000 entries processed\n",
      "1390000 entries processed\n",
      "1391000 entries processed\n",
      "1392000 entries processed\n",
      "1393000 entries processed\n",
      "1394000 entries processed\n",
      "1395000 entries processed\n",
      "1396000 entries processed\n",
      "1397000 entries processed\n",
      "1398000 entries processed\n",
      "1399000 entries processed\n",
      "1400000 entries processed\n",
      "1401000 entries processed\n",
      "1402000 entries processed\n",
      "1403000 entries processed\n",
      "1404000 entries processed\n",
      "1405000 entries processed\n",
      "1406000 entries processed\n",
      "1407000 entries processed\n",
      "1408000 entries processed\n",
      "1409000 entries processed\n",
      "1410000 entries processed\n",
      "1411000 entries processed\n",
      "1412000 entries processed\n",
      "1413000 entries processed\n",
      "1414000 entries processed\n",
      "1415000 entries processed\n",
      "1416000 entries processed\n",
      "1417000 entries processed\n",
      "1418000 entries processed\n",
      "1419000 entries processed\n",
      "1420000 entries processed\n",
      "1421000 entries processed\n",
      "1422000 entries processed\n",
      "1423000 entries processed\n",
      "1424000 entries processed\n",
      "1425000 entries processed\n",
      "1426000 entries processed\n",
      "1427000 entries processed\n",
      "1428000 entries processed\n",
      "1429000 entries processed\n",
      "1430000 entries processed\n",
      "1431000 entries processed\n",
      "1432000 entries processed\n",
      "1433000 entries processed\n",
      "1434000 entries processed\n",
      "1435000 entries processed\n",
      "1436000 entries processed\n",
      "1437000 entries processed\n",
      "1438000 entries processed\n",
      "1439000 entries processed\n",
      "1440000 entries processed\n",
      "1441000 entries processed\n",
      "1442000 entries processed\n",
      "1443000 entries processed\n",
      "1444000 entries processed\n",
      "1445000 entries processed\n",
      "1446000 entries processed\n",
      "1447000 entries processed\n",
      "1448000 entries processed\n",
      "1449000 entries processed\n",
      "1450000 entries processed\n",
      "1451000 entries processed\n",
      "1452000 entries processed\n",
      "1453000 entries processed\n",
      "1454000 entries processed\n",
      "1455000 entries processed\n",
      "1456000 entries processed\n",
      "1457000 entries processed\n",
      "1458000 entries processed\n",
      "1459000 entries processed\n",
      "1460000 entries processed\n",
      "1461000 entries processed\n",
      "1462000 entries processed\n",
      "1463000 entries processed\n",
      "1464000 entries processed\n",
      "1465000 entries processed\n",
      "1466000 entries processed\n",
      "1467000 entries processed\n",
      "1468000 entries processed\n",
      "1469000 entries processed\n",
      "1470000 entries processed\n",
      "1471000 entries processed\n",
      "1472000 entries processed\n",
      "1473000 entries processed\n",
      "1474000 entries processed\n",
      "1475000 entries processed\n",
      "1476000 entries processed\n",
      "1477000 entries processed\n",
      "1478000 entries processed\n",
      "1479000 entries processed\n",
      "1480000 entries processed\n",
      "1481000 entries processed\n",
      "1482000 entries processed\n",
      "1483000 entries processed\n",
      "1484000 entries processed\n",
      "1485000 entries processed\n",
      "1486000 entries processed\n",
      "1487000 entries processed\n",
      "1488000 entries processed\n",
      "1489000 entries processed\n",
      "1490000 entries processed\n",
      "1491000 entries processed\n",
      "1492000 entries processed\n",
      "1493000 entries processed\n",
      "1494000 entries processed\n",
      "1495000 entries processed\n",
      "1496000 entries processed\n",
      "1497000 entries processed\n",
      "1498000 entries processed\n",
      "1499000 entries processed\n",
      "1500000 entries processed\n",
      "1501000 entries processed\n",
      "1502000 entries processed\n",
      "1503000 entries processed\n",
      "1504000 entries processed\n",
      "1505000 entries processed\n",
      "1506000 entries processed\n",
      "1507000 entries processed\n",
      "1508000 entries processed\n",
      "1509000 entries processed\n",
      "1510000 entries processed\n",
      "1511000 entries processed\n",
      "1512000 entries processed\n",
      "1513000 entries processed\n",
      "1514000 entries processed\n",
      "1515000 entries processed\n",
      "1516000 entries processed\n",
      "1517000 entries processed\n",
      "1518000 entries processed\n",
      "1519000 entries processed\n",
      "1520000 entries processed\n",
      "1521000 entries processed\n",
      "1522000 entries processed\n",
      "1523000 entries processed\n",
      "1524000 entries processed\n",
      "1525000 entries processed\n",
      "1526000 entries processed\n",
      "1527000 entries processed\n",
      "1528000 entries processed\n",
      "1529000 entries processed\n",
      "1530000 entries processed\n",
      "1531000 entries processed\n",
      "1532000 entries processed\n",
      "1533000 entries processed\n",
      "1534000 entries processed\n",
      "1535000 entries processed\n",
      "1536000 entries processed\n",
      "1537000 entries processed\n",
      "1538000 entries processed\n",
      "1539000 entries processed\n",
      "1540000 entries processed\n",
      "1541000 entries processed\n",
      "1542000 entries processed\n",
      "1543000 entries processed\n",
      "1544000 entries processed\n",
      "1545000 entries processed\n",
      "1546000 entries processed\n",
      "1547000 entries processed\n",
      "1548000 entries processed\n",
      "1549000 entries processed\n",
      "1550000 entries processed\n",
      "1551000 entries processed\n",
      "1552000 entries processed\n",
      "1553000 entries processed\n",
      "1554000 entries processed\n",
      "1555000 entries processed\n",
      "1556000 entries processed\n",
      "1557000 entries processed\n",
      "1558000 entries processed\n",
      "1559000 entries processed\n",
      "1560000 entries processed\n",
      "1561000 entries processed\n",
      "1562000 entries processed\n",
      "1563000 entries processed\n",
      "1564000 entries processed\n",
      "1565000 entries processed\n",
      "1566000 entries processed\n",
      "1567000 entries processed\n",
      "1568000 entries processed\n",
      "1569000 entries processed\n",
      "1570000 entries processed\n",
      "1571000 entries processed\n",
      "1572000 entries processed\n",
      "1573000 entries processed\n",
      "1574000 entries processed\n",
      "1575000 entries processed\n",
      "1576000 entries processed\n",
      "1577000 entries processed\n",
      "1578000 entries processed\n",
      "1579000 entries processed\n",
      "1580000 entries processed\n",
      "1581000 entries processed\n",
      "1582000 entries processed\n",
      "1583000 entries processed\n",
      "1584000 entries processed\n",
      "1585000 entries processed\n",
      "1586000 entries processed\n",
      "1587000 entries processed\n",
      "1588000 entries processed\n",
      "1589000 entries processed\n",
      "1590000 entries processed\n",
      "1591000 entries processed\n",
      "1592000 entries processed\n",
      "1593000 entries processed\n",
      "1594000 entries processed\n",
      "1595000 entries processed\n",
      "1596000 entries processed\n",
      "1597000 entries processed\n",
      "1598000 entries processed\n",
      "1599000 entries processed\n",
      "1600000 entries processed\n",
      "1601000 entries processed\n",
      "1602000 entries processed\n",
      "1603000 entries processed\n",
      "1604000 entries processed\n",
      "1605000 entries processed\n",
      "1606000 entries processed\n",
      "1607000 entries processed\n",
      "1608000 entries processed\n",
      "1609000 entries processed\n",
      "1610000 entries processed\n",
      "1611000 entries processed\n",
      "1612000 entries processed\n",
      "1613000 entries processed\n",
      "1614000 entries processed\n",
      "1615000 entries processed\n",
      "1616000 entries processed\n",
      "1617000 entries processed\n",
      "1618000 entries processed\n",
      "1619000 entries processed\n",
      "1620000 entries processed\n",
      "1621000 entries processed\n",
      "1622000 entries processed\n",
      "1623000 entries processed\n",
      "1624000 entries processed\n",
      "1625000 entries processed\n",
      "1626000 entries processed\n",
      "1627000 entries processed\n",
      "1628000 entries processed\n",
      "1629000 entries processed\n",
      "1630000 entries processed\n",
      "1631000 entries processed\n",
      "1632000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633000 entries processed\n",
      "1634000 entries processed\n",
      "1635000 entries processed\n",
      "1636000 entries processed\n",
      "1637000 entries processed\n",
      "1638000 entries processed\n",
      "1639000 entries processed\n",
      "1640000 entries processed\n",
      "1641000 entries processed\n",
      "1642000 entries processed\n",
      "1643000 entries processed\n",
      "1644000 entries processed\n",
      "1645000 entries processed\n",
      "1646000 entries processed\n",
      "1647000 entries processed\n",
      "1648000 entries processed\n",
      "1649000 entries processed\n",
      "1650000 entries processed\n",
      "1651000 entries processed\n",
      "1652000 entries processed\n",
      "1653000 entries processed\n",
      "1654000 entries processed\n",
      "1655000 entries processed\n",
      "1656000 entries processed\n",
      "1657000 entries processed\n",
      "1658000 entries processed\n",
      "1659000 entries processed\n",
      "1660000 entries processed\n",
      "1661000 entries processed\n",
      "1662000 entries processed\n",
      "1663000 entries processed\n",
      "1664000 entries processed\n",
      "1665000 entries processed\n",
      "1666000 entries processed\n",
      "1667000 entries processed\n",
      "1668000 entries processed\n",
      "1669000 entries processed\n",
      "1670000 entries processed\n",
      "1671000 entries processed\n",
      "1672000 entries processed\n",
      "1673000 entries processed\n",
      "1674000 entries processed\n",
      "1675000 entries processed\n",
      "1676000 entries processed\n",
      "1677000 entries processed\n",
      "1678000 entries processed\n",
      "1679000 entries processed\n",
      "1680000 entries processed\n",
      "1681000 entries processed\n",
      "1682000 entries processed\n",
      "1683000 entries processed\n",
      "1684000 entries processed\n",
      "1685000 entries processed\n",
      "1686000 entries processed\n",
      "1687000 entries processed\n",
      "1688000 entries processed\n",
      "1689000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/birthYear>\n",
      "1690000 entries processed\n",
      "1691000 entries processed\n",
      "1692000 entries processed\n",
      "1693000 entries processed\n",
      "1694000 entries processed\n",
      "1695000 entries processed\n",
      "1696000 entries processed\n",
      "1697000 entries processed\n",
      "1698000 entries processed\n",
      "1699000 entries processed\n",
      "1700000 entries processed\n",
      "1701000 entries processed\n",
      "1702000 entries processed\n",
      "1703000 entries processed\n",
      "1704000 entries processed\n",
      "1705000 entries processed\n",
      "1706000 entries processed\n",
      "1707000 entries processed\n",
      "1708000 entries processed\n",
      "1709000 entries processed\n",
      "1710000 entries processed\n",
      "1711000 entries processed\n",
      "1712000 entries processed\n",
      "1713000 entries processed\n",
      "1714000 entries processed\n",
      "1715000 entries processed\n",
      "1716000 entries processed\n",
      "1717000 entries processed\n",
      "1718000 entries processed\n",
      "1719000 entries processed\n",
      "1720000 entries processed\n",
      "1721000 entries processed\n",
      "1722000 entries processed\n",
      "1723000 entries processed\n",
      "1724000 entries processed\n",
      "1725000 entries processed\n",
      "1726000 entries processed\n",
      "1727000 entries processed\n",
      "1728000 entries processed\n",
      "1729000 entries processed\n",
      "1730000 entries processed\n",
      "1731000 entries processed\n",
      "1732000 entries processed\n",
      "1733000 entries processed\n",
      "1734000 entries processed\n",
      "1735000 entries processed\n",
      "1736000 entries processed\n",
      "1737000 entries processed\n",
      "1738000 entries processed\n",
      "1739000 entries processed\n",
      "1740000 entries processed\n",
      "1741000 entries processed\n",
      "1742000 entries processed\n",
      "1743000 entries processed\n",
      "1744000 entries processed\n",
      "1745000 entries processed\n",
      "1746000 entries processed\n",
      "1747000 entries processed\n",
      "1748000 entries processed\n",
      "1749000 entries processed\n",
      "1750000 entries processed\n",
      "1751000 entries processed\n",
      "1752000 entries processed\n",
      "1753000 entries processed\n",
      "1754000 entries processed\n",
      "1755000 entries processed\n",
      "1756000 entries processed\n",
      "1757000 entries processed\n",
      "1758000 entries processed\n",
      "1759000 entries processed\n",
      "1760000 entries processed\n",
      "1761000 entries processed\n",
      "1762000 entries processed\n",
      "1763000 entries processed\n",
      "1764000 entries processed\n",
      "1765000 entries processed\n",
      "1766000 entries processed\n",
      "1767000 entries processed\n",
      "1768000 entries processed\n",
      "1769000 entries processed\n",
      "1770000 entries processed\n",
      "1771000 entries processed\n",
      "1772000 entries processed\n",
      "1773000 entries processed\n",
      "1774000 entries processed\n",
      "1775000 entries processed\n",
      "1776000 entries processed\n",
      "1777000 entries processed\n",
      "1778000 entries processed\n",
      "1779000 entries processed\n",
      "1780000 entries processed\n",
      "1781000 entries processed\n",
      "1782000 entries processed\n",
      "1783000 entries processed\n",
      "1784000 entries processed\n",
      "1785000 entries processed\n",
      "1786000 entries processed\n",
      "1787000 entries processed\n",
      "1788000 entries processed\n",
      "1789000 entries processed\n",
      "1790000 entries processed\n",
      "1791000 entries processed\n",
      "1792000 entries processed\n",
      "1793000 entries processed\n",
      "1794000 entries processed\n",
      "1795000 entries processed\n",
      "1796000 entries processed\n",
      "1797000 entries processed\n",
      "1798000 entries processed\n",
      "1799000 entries processed\n",
      "1800000 entries processed\n",
      "1801000 entries processed\n",
      "1802000 entries processed\n",
      "1803000 entries processed\n",
      "1804000 entries processed\n",
      "1805000 entries processed\n",
      "1806000 entries processed\n",
      "1807000 entries processed\n",
      "1808000 entries processed\n",
      "1809000 entries processed\n",
      "1810000 entries processed\n",
      "1811000 entries processed\n",
      "1812000 entries processed\n",
      "1813000 entries processed\n",
      "1814000 entries processed\n",
      "1815000 entries processed\n",
      "1816000 entries processed\n",
      "1817000 entries processed\n",
      "1818000 entries processed\n",
      "1819000 entries processed\n",
      "1820000 entries processed\n",
      "1821000 entries processed\n",
      "1822000 entries processed\n",
      "1823000 entries processed\n",
      "1824000 entries processed\n",
      "1825000 entries processed\n",
      "1826000 entries processed\n",
      "1827000 entries processed\n",
      "1828000 entries processed\n",
      "1829000 entries processed\n",
      "1830000 entries processed\n",
      "1831000 entries processed\n",
      "1832000 entries processed\n",
      "1833000 entries processed\n",
      "1834000 entries processed\n",
      "1835000 entries processed\n",
      "1836000 entries processed\n",
      "1837000 entries processed\n",
      "1838000 entries processed\n",
      "1839000 entries processed\n",
      "1840000 entries processed\n",
      "1841000 entries processed\n",
      "1842000 entries processed\n",
      "1843000 entries processed\n",
      "1844000 entries processed\n",
      "1845000 entries processed\n",
      "1846000 entries processed\n",
      "1847000 entries processed\n",
      "1848000 entries processed\n",
      "1849000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/budget>\n",
      "1850000 entries processed\n",
      "1851000 entries processed\n",
      "1852000 entries processed\n",
      "1853000 entries processed\n",
      "1854000 entries processed\n",
      "1855000 entries processed\n",
      "1856000 entries processed\n",
      "1857000 entries processed\n",
      "1858000 entries processed\n",
      "1859000 entries processed\n",
      "1860000 entries processed\n",
      "1861000 entries processed\n",
      "1862000 entries processed\n",
      "1863000 entries processed\n",
      "1864000 entries processed\n",
      "1865000 entries processed\n",
      "1866000 entries processed\n",
      "1867000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/buildingEndYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/buildingStartYear>\n",
      "1868000 entries processed\n",
      "1869000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/bustSize>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/campusSize>\n",
      "1870000 entries processed\n",
      "1871000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/canonizedDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/capacity>\n",
      "1872000 entries processed\n",
      "1873000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874000 entries processed\n",
      "1875000 entries processed\n",
      "1876000 entries processed\n",
      "1877000 entries processed\n",
      "1878000 entries processed\n",
      "1879000 entries processed\n",
      "1880000 entries processed\n",
      "1881000 entries processed\n",
      "1882000 entries processed\n",
      "1883000 entries processed\n",
      "1884000 entries processed\n",
      "1885000 entries processed\n",
      "1886000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/capacityFactor>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/capitalElevation>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/captureDate>\n",
      "1887000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/carNumber>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/carbohydrate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/careerPrizeMoney>\n",
      "1890000 entries processed\n",
      "1891000 entries processed\n",
      "1892000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/casualties>\n",
      "1893000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/censusYear>\n",
      "1894000 entries processed\n",
      "1895000 entries processed\n",
      "1896000 entries processed\n",
      "1897000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/centuryBreaks>\n",
      "1898000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/certificationDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/championships>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/christeningDate>\n",
      "1899000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/circulation>\n",
      "1900000 entries processed\n",
      "1901000 entries processed\n",
      "1902000 entries processed\n",
      "1903000 entries processed\n",
      "1904000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/classes>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/closed>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/closingDate>\n",
      "1905000 entries processed\n",
      "1906000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/closingYear>\n",
      "1907000 entries processed\n",
      "1908000 entries processed\n",
      "1909000 entries processed\n",
      "1910000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cmykCoordinateBlack>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cmykCoordinateCyanic>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cmykCoordinateMagenta>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cmykCoordinateYellow>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/co2Emission>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/commissioningDate>\n",
      "1915000 entries processed\n",
      "1916000 entries processed\n",
      "1917000 entries processed\n",
      "1918000 entries processed\n",
      "1919000 entries processed\n",
      "1920000 entries processed\n",
      "1921000 entries processed\n",
      "1922000 entries processed\n",
      "1923000 entries processed\n",
      "1924000 entries processed\n",
      "1925000 entries processed\n",
      "1926000 entries processed\n",
      "1927000 entries processed\n",
      "1928000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/completionDate>\n",
      "1929000 entries processed\n",
      "1930000 entries processed\n",
      "1931000 entries processed\n",
      "1932000 entries processed\n",
      "1933000 entries processed\n",
      "1934000 entries processed\n",
      "1935000 entries processed\n",
      "1936000 entries processed\n",
      "1937000 entries processed\n",
      "1938000 entries processed\n",
      "1939000 entries processed\n",
      "1940000 entries processed\n",
      "1941000 entries processed\n",
      "1942000 entries processed\n",
      "1943000 entries processed\n",
      "1944000 entries processed\n",
      "1945000 entries processed\n",
      "1946000 entries processed\n",
      "1947000 entries processed\n",
      "1948000 entries processed\n",
      "1949000 entries processed\n",
      "1950000 entries processed\n",
      "1951000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/contractAward>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cost>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952000 entries processed\n",
      "1953000 entries processed\n",
      "1954000 entries processed\n",
      "1955000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/course>\n",
      "1956000 entries processed\n",
      "1957000 entries processed\n",
      "1958000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/crews>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/currentRank>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cylinderBore>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/cylinderCount>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/date>\n",
      "1960000 entries processed\n",
      "1961000 entries processed\n",
      "1962000 entries processed\n",
      "1963000 entries processed\n",
      "1964000 entries processed\n",
      "1965000 entries processed\n",
      "1966000 entries processed\n",
      "1967000 entries processed\n",
      "1968000 entries processed\n",
      "1969000 entries processed\n",
      "1970000 entries processed\n",
      "1971000 entries processed\n",
      "1972000 entries processed\n",
      "1973000 entries processed\n",
      "1974000 entries processed\n",
      "1975000 entries processed\n",
      "1976000 entries processed\n",
      "1977000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateAct>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateCompleted>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateConstruction>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateOfAbandonment>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateOfBurial>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dateUse>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/day>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/deathDate>\n",
      "1978000 entries processed\n",
      "1979000 entries processed\n",
      "1980000 entries processed\n",
      "1981000 entries processed\n",
      "1982000 entries processed\n",
      "1983000 entries processed\n",
      "1984000 entries processed\n",
      "1985000 entries processed\n",
      "1986000 entries processed\n",
      "1987000 entries processed\n",
      "1988000 entries processed\n",
      "1989000 entries processed\n",
      "1990000 entries processed\n",
      "1991000 entries processed\n",
      "1992000 entries processed\n",
      "1993000 entries processed\n",
      "1994000 entries processed\n",
      "1995000 entries processed\n",
      "1996000 entries processed\n",
      "1997000 entries processed\n",
      "1998000 entries processed\n",
      "1999000 entries processed\n",
      "2000000 entries processed\n",
      "2001000 entries processed\n",
      "2002000 entries processed\n",
      "2003000 entries processed\n",
      "2004000 entries processed\n",
      "2005000 entries processed\n",
      "2006000 entries processed\n",
      "2007000 entries processed\n",
      "2008000 entries processed\n",
      "2009000 entries processed\n",
      "2010000 entries processed\n",
      "2011000 entries processed\n",
      "2012000 entries processed\n",
      "2013000 entries processed\n",
      "2014000 entries processed\n",
      "2015000 entries processed\n",
      "2016000 entries processed\n",
      "2017000 entries processed\n",
      "2018000 entries processed\n",
      "2019000 entries processed\n",
      "2020000 entries processed\n",
      "2021000 entries processed\n",
      "2022000 entries processed\n",
      "2023000 entries processed\n",
      "2024000 entries processed\n",
      "2025000 entries processed\n",
      "2026000 entries processed\n",
      "2027000 entries processed\n",
      "2028000 entries processed\n",
      "2029000 entries processed\n",
      "2030000 entries processed\n",
      "2031000 entries processed\n",
      "2032000 entries processed\n",
      "2033000 entries processed\n",
      "2034000 entries processed\n",
      "2035000 entries processed\n",
      "2036000 entries processed\n",
      "2037000 entries processed\n",
      "2038000 entries processed\n",
      "2039000 entries processed\n",
      "2040000 entries processed\n",
      "2041000 entries processed\n",
      "2042000 entries processed\n",
      "2043000 entries processed\n",
      "2044000 entries processed\n",
      "2045000 entries processed\n",
      "2046000 entries processed\n",
      "2047000 entries processed\n",
      "2048000 entries processed\n",
      "2049000 entries processed\n",
      "2050000 entries processed\n",
      "2051000 entries processed\n",
      "2052000 entries processed\n",
      "2053000 entries processed\n",
      "2054000 entries processed\n",
      "2055000 entries processed\n",
      "2056000 entries processed\n",
      "2057000 entries processed\n",
      "2058000 entries processed\n",
      "2059000 entries processed\n",
      "2060000 entries processed\n",
      "2061000 entries processed\n",
      "2062000 entries processed\n",
      "2063000 entries processed\n",
      "2064000 entries processed\n",
      "2065000 entries processed\n",
      "2066000 entries processed\n",
      "2067000 entries processed\n",
      "2068000 entries processed\n",
      "2069000 entries processed\n",
      "2070000 entries processed\n",
      "2071000 entries processed\n",
      "2072000 entries processed\n",
      "2073000 entries processed\n",
      "2074000 entries processed\n",
      "2075000 entries processed\n",
      "2076000 entries processed\n",
      "2077000 entries processed\n",
      "2078000 entries processed\n",
      "2079000 entries processed\n",
      "2080000 entries processed\n",
      "2081000 entries processed\n",
      "2082000 entries processed\n",
      "2083000 entries processed\n",
      "2084000 entries processed\n",
      "2085000 entries processed\n",
      "2086000 entries processed\n",
      "2087000 entries processed\n",
      "2088000 entries processed\n",
      "2089000 entries processed\n",
      "2090000 entries processed\n",
      "2091000 entries processed\n",
      "2092000 entries processed\n",
      "2093000 entries processed\n",
      "2094000 entries processed\n",
      "2095000 entries processed\n",
      "2096000 entries processed\n",
      "2097000 entries processed\n",
      "2098000 entries processed\n",
      "2099000 entries processed\n",
      "2100000 entries processed\n",
      "2101000 entries processed\n",
      "2102000 entries processed\n",
      "2103000 entries processed\n",
      "2104000 entries processed\n",
      "2105000 entries processed\n",
      "2106000 entries processed\n",
      "2107000 entries processed\n",
      "2108000 entries processed\n",
      "2109000 entries processed\n",
      "2110000 entries processed\n",
      "2111000 entries processed\n",
      "2112000 entries processed\n",
      "2113000 entries processed\n",
      "2114000 entries processed\n",
      "2115000 entries processed\n",
      "2116000 entries processed\n",
      "2117000 entries processed\n",
      "2118000 entries processed\n",
      "2119000 entries processed\n",
      "2120000 entries processed\n",
      "2121000 entries processed\n",
      "2122000 entries processed\n",
      "2123000 entries processed\n",
      "2124000 entries processed\n",
      "2125000 entries processed\n",
      "2126000 entries processed\n",
      "2127000 entries processed\n",
      "2128000 entries processed\n",
      "2129000 entries processed\n",
      "2130000 entries processed\n",
      "2131000 entries processed\n",
      "2132000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133000 entries processed\n",
      "2134000 entries processed\n",
      "2135000 entries processed\n",
      "2136000 entries processed\n",
      "2137000 entries processed\n",
      "2138000 entries processed\n",
      "2139000 entries processed\n",
      "2140000 entries processed\n",
      "2141000 entries processed\n",
      "2142000 entries processed\n",
      "2143000 entries processed\n",
      "2144000 entries processed\n",
      "2145000 entries processed\n",
      "2146000 entries processed\n",
      "2147000 entries processed\n",
      "2148000 entries processed\n",
      "2149000 entries processed\n",
      "2150000 entries processed\n",
      "2151000 entries processed\n",
      "2152000 entries processed\n",
      "2153000 entries processed\n",
      "2154000 entries processed\n",
      "2155000 entries processed\n",
      "2156000 entries processed\n",
      "2157000 entries processed\n",
      "2158000 entries processed\n",
      "2159000 entries processed\n",
      "2160000 entries processed\n",
      "2161000 entries processed\n",
      "2162000 entries processed\n",
      "2163000 entries processed\n",
      "2164000 entries processed\n",
      "2165000 entries processed\n",
      "2166000 entries processed\n",
      "2167000 entries processed\n",
      "2168000 entries processed\n",
      "2169000 entries processed\n",
      "2170000 entries processed\n",
      "2171000 entries processed\n",
      "2172000 entries processed\n",
      "2173000 entries processed\n",
      "2174000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/deathYear>\n",
      "2175000 entries processed\n",
      "2176000 entries processed\n",
      "2177000 entries processed\n",
      "2178000 entries processed\n",
      "2179000 entries processed\n",
      "2180000 entries processed\n",
      "2181000 entries processed\n",
      "2182000 entries processed\n",
      "2183000 entries processed\n",
      "2184000 entries processed\n",
      "2185000 entries processed\n",
      "2186000 entries processed\n",
      "2187000 entries processed\n",
      "2188000 entries processed\n",
      "2189000 entries processed\n",
      "2190000 entries processed\n",
      "2191000 entries processed\n",
      "2192000 entries processed\n",
      "2193000 entries processed\n",
      "2194000 entries processed\n",
      "2195000 entries processed\n",
      "2196000 entries processed\n",
      "2197000 entries processed\n",
      "2198000 entries processed\n",
      "2199000 entries processed\n",
      "2200000 entries processed\n",
      "2201000 entries processed\n",
      "2202000 entries processed\n",
      "2203000 entries processed\n",
      "2204000 entries processed\n",
      "2205000 entries processed\n",
      "2206000 entries processed\n",
      "2207000 entries processed\n",
      "2208000 entries processed\n",
      "2209000 entries processed\n",
      "2210000 entries processed\n",
      "2211000 entries processed\n",
      "2212000 entries processed\n",
      "2213000 entries processed\n",
      "2214000 entries processed\n",
      "2215000 entries processed\n",
      "2216000 entries processed\n",
      "2217000 entries processed\n",
      "2218000 entries processed\n",
      "2219000 entries processed\n",
      "2220000 entries processed\n",
      "2221000 entries processed\n",
      "2222000 entries processed\n",
      "2223000 entries processed\n",
      "2224000 entries processed\n",
      "2225000 entries processed\n",
      "2226000 entries processed\n",
      "2227000 entries processed\n",
      "2228000 entries processed\n",
      "2229000 entries processed\n",
      "2230000 entries processed\n",
      "2231000 entries processed\n",
      "2232000 entries processed\n",
      "2233000 entries processed\n",
      "2234000 entries processed\n",
      "2235000 entries processed\n",
      "2236000 entries processed\n",
      "2237000 entries processed\n",
      "2238000 entries processed\n",
      "2239000 entries processed\n",
      "2240000 entries processed\n",
      "2241000 entries processed\n",
      "2242000 entries processed\n",
      "2243000 entries processed\n",
      "2244000 entries processed\n",
      "2245000 entries processed\n",
      "2246000 entries processed\n",
      "2247000 entries processed\n",
      "2248000 entries processed\n",
      "2249000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/debut>\n",
      "2250000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/decideDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/declination>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/decommissioningDate>\n",
      "2251000 entries processed\n",
      "2252000 entries processed\n",
      "2253000 entries processed\n",
      "2254000 entries processed\n",
      "2255000 entries processed\n",
      "2256000 entries processed\n",
      "2257000 entries processed\n",
      "2258000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/deliveryDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/demolitionDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/demolitionYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/density>\n",
      "2259000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/depth>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/destructionDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/diameter>\n",
      "2260000 entries processed\n",
      "2261000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/disbanded>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/discharge>\n",
      "2262000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dischargeAverage>\n",
      "2263000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/discovered>\n",
      "2264000 entries processed\n",
      "2265000 entries processed\n",
      "2266000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/displacement>\n",
      "2273000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dissolutionDate>\n",
      "2283000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dissolutionYear>\n",
      "2284000 entries processed\n",
      "2285000 entries processed\n",
      "2286000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/dissolved>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distance>\n",
      "2287000 entries processed\n",
      "2288000 entries processed\n",
      "2289000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceLaps>\n",
      "2290000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToBelfast>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToCardiff>\n",
      "2291000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToCharingCross>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToDouglas>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToDublin>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToEdinburgh>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/distanceToLondon>\n",
      "2292000 entries processed\n",
      "2293000 entries processed\n",
      "2294000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/draftYear>\n",
      "2296000 entries processed\n",
      "2297000 entries processed\n",
      "2298000 entries processed\n",
      "2299000 entries processed\n",
      "2300000 entries processed\n",
      "2301000 entries processed\n",
      "2302000 entries processed\n",
      "2303000 entries processed\n",
      "2304000 entries processed\n",
      "2305000 entries processed\n",
      "2306000 entries processed\n",
      "2307000 entries processed\n",
      "2308000 entries processed\n",
      "2309000 entries processed\n",
      "2310000 entries processed\n",
      "2311000 entries processed\n",
      "2312000 entries processed\n",
      "2313000 entries processed\n",
      "2314000 entries processed\n",
      "2315000 entries processed\n",
      "2316000 entries processed\n",
      "2317000 entries processed\n",
      "2318000 entries processed\n",
      "2319000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/duration>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/effectiveRadiatedPower>\n",
      "2320000 entries processed\n",
      "2321000 entries processed\n",
      "2322000 entries processed\n",
      "2323000 entries processed\n",
      "2324000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/electionDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/electionDateLeader>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/electionMajority>\n",
      "2325000 entries processed\n",
      "2326000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/elevation>\n",
      "2327000 entries processed\n",
      "2328000 entries processed\n",
      "2329000 entries processed\n",
      "2330000 entries processed\n",
      "2331000 entries processed\n",
      "2332000 entries processed\n",
      "2333000 entries processed\n",
      "2334000 entries processed\n",
      "2335000 entries processed\n",
      "2336000 entries processed\n",
      "2337000 entries processed\n",
      "2338000 entries processed\n",
      "2339000 entries processed\n",
      "2340000 entries processed\n",
      "2341000 entries processed\n",
      "2342000 entries processed\n",
      "2343000 entries processed\n",
      "2344000 entries processed\n",
      "2345000 entries processed\n",
      "2346000 entries processed\n",
      "2347000 entries processed\n",
      "2348000 entries processed\n",
      "2349000 entries processed\n",
      "2350000 entries processed\n",
      "2351000 entries processed\n",
      "2352000 entries processed\n",
      "2353000 entries processed\n",
      "2354000 entries processed\n",
      "2355000 entries processed\n",
      "2356000 entries processed\n",
      "2357000 entries processed\n",
      "2358000 entries processed\n",
      "2359000 entries processed\n",
      "2360000 entries processed\n",
      "2361000 entries processed\n",
      "2362000 entries processed\n",
      "2363000 entries processed\n",
      "2364000 entries processed\n",
      "2365000 entries processed\n",
      "2366000 entries processed\n",
      "2367000 entries processed\n",
      "2368000 entries processed\n",
      "2369000 entries processed\n",
      "2370000 entries processed\n",
      "2371000 entries processed\n",
      "2372000 entries processed\n",
      "2373000 entries processed\n",
      "2374000 entries processed\n",
      "2375000 entries processed\n",
      "2376000 entries processed\n",
      "2377000 entries processed\n",
      "2378000 entries processed\n",
      "2379000 entries processed\n",
      "2380000 entries processed\n",
      "2381000 entries processed\n",
      "2382000 entries processed\n",
      "2383000 entries processed\n",
      "2384000 entries processed\n",
      "2385000 entries processed\n",
      "2386000 entries processed\n",
      "2387000 entries processed\n",
      "2388000 entries processed\n",
      "2389000 entries processed\n",
      "2390000 entries processed\n",
      "2391000 entries processed\n",
      "2392000 entries processed\n",
      "2393000 entries processed\n",
      "2394000 entries processed\n",
      "2395000 entries processed\n",
      "2396000 entries processed\n",
      "2397000 entries processed\n",
      "2398000 entries processed\n",
      "2399000 entries processed\n",
      "2400000 entries processed\n",
      "2401000 entries processed\n",
      "2402000 entries processed\n",
      "2403000 entries processed\n",
      "2404000 entries processed\n",
      "2405000 entries processed\n",
      "2406000 entries processed\n",
      "2407000 entries processed\n",
      "2408000 entries processed\n",
      "2409000 entries processed\n",
      "2410000 entries processed\n",
      "2411000 entries processed\n",
      "2412000 entries processed\n",
      "2413000 entries processed\n",
      "2414000 entries processed\n",
      "2415000 entries processed\n",
      "2416000 entries processed\n",
      "2417000 entries processed\n",
      "2418000 entries processed\n",
      "2419000 entries processed\n",
      "2420000 entries processed\n",
      "2421000 entries processed\n",
      "2422000 entries processed\n",
      "2423000 entries processed\n",
      "2424000 entries processed\n",
      "2425000 entries processed\n",
      "2426000 entries processed\n",
      "2428000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429000 entries processed\n",
      "2430000 entries processed\n",
      "2431000 entries processed\n",
      "2432000 entries processed\n",
      "2433000 entries processed\n",
      "2434000 entries processed\n",
      "2435000 entries processed\n",
      "2436000 entries processed\n",
      "2437000 entries processed\n",
      "2438000 entries processed\n",
      "2439000 entries processed\n",
      "2440000 entries processed\n",
      "2441000 entries processed\n",
      "2442000 entries processed\n",
      "2443000 entries processed\n",
      "2444000 entries processed\n",
      "2445000 entries processed\n",
      "2446000 entries processed\n",
      "2447000 entries processed\n",
      "2448000 entries processed\n",
      "2449000 entries processed\n",
      "2450000 entries processed\n",
      "2451000 entries processed\n",
      "2452000 entries processed\n",
      "2453000 entries processed\n",
      "2454000 entries processed\n",
      "2455000 entries processed\n",
      "2456000 entries processed\n",
      "2457000 entries processed\n",
      "2458000 entries processed\n",
      "2459000 entries processed\n",
      "2460000 entries processed\n",
      "2461000 entries processed\n",
      "2462000 entries processed\n",
      "2463000 entries processed\n",
      "2464000 entries processed\n",
      "2465000 entries processed\n",
      "2466000 entries processed\n",
      "2467000 entries processed\n",
      "2468000 entries processed\n",
      "2469000 entries processed\n",
      "2470000 entries processed\n",
      "2471000 entries processed\n",
      "2472000 entries processed\n",
      "2473000 entries processed\n",
      "2474000 entries processed\n",
      "2475000 entries processed\n",
      "2476000 entries processed\n",
      "2477000 entries processed\n",
      "2478000 entries processed\n",
      "2479000 entries processed\n",
      "2480000 entries processed\n",
      "2481000 entries processed\n",
      "2482000 entries processed\n",
      "2483000 entries processed\n",
      "2484000 entries processed\n",
      "2485000 entries processed\n",
      "2486000 entries processed\n",
      "2487000 entries processed\n",
      "2488000 entries processed\n",
      "2489000 entries processed\n",
      "2490000 entries processed\n",
      "2491000 entries processed\n",
      "2492000 entries processed\n",
      "2493000 entries processed\n",
      "2494000 entries processed\n",
      "2495000 entries processed\n",
      "2496000 entries processed\n",
      "2497000 entries processed\n",
      "2498000 entries processed\n",
      "2499000 entries processed\n",
      "2500000 entries processed\n",
      "2501000 entries processed\n",
      "2502000 entries processed\n",
      "2503000 entries processed\n",
      "2504000 entries processed\n",
      "2505000 entries processed\n",
      "2506000 entries processed\n",
      "2507000 entries processed\n",
      "2508000 entries processed\n",
      "2509000 entries processed\n",
      "2510000 entries processed\n",
      "2511000 entries processed\n",
      "2512000 entries processed\n",
      "2513000 entries processed\n",
      "2514000 entries processed\n",
      "2515000 entries processed\n",
      "2516000 entries processed\n",
      "2517000 entries processed\n",
      "2518000 entries processed\n",
      "2519000 entries processed\n",
      "2520000 entries processed\n",
      "2521000 entries processed\n",
      "2522000 entries processed\n",
      "2523000 entries processed\n",
      "2524000 entries processed\n",
      "2525000 entries processed\n",
      "2526000 entries processed\n",
      "2527000 entries processed\n",
      "2528000 entries processed\n",
      "2529000 entries processed\n",
      "2530000 entries processed\n",
      "2531000 entries processed\n",
      "2532000 entries processed\n",
      "2533000 entries processed\n",
      "2534000 entries processed\n",
      "2535000 entries processed\n",
      "2536000 entries processed\n",
      "2537000 entries processed\n",
      "2538000 entries processed\n",
      "2539000 entries processed\n",
      "2540000 entries processed\n",
      "2541000 entries processed\n",
      "2542000 entries processed\n",
      "2543000 entries processed\n",
      "2544000 entries processed\n",
      "2545000 entries processed\n",
      "2546000 entries processed\n",
      "2547000 entries processed\n",
      "2548000 entries processed\n",
      "2549000 entries processed\n",
      "2550000 entries processed\n",
      "2551000 entries processed\n",
      "2552000 entries processed\n",
      "2553000 entries processed\n",
      "2554000 entries processed\n",
      "2555000 entries processed\n",
      "2556000 entries processed\n",
      "2557000 entries processed\n",
      "2558000 entries processed\n",
      "2559000 entries processed\n",
      "2560000 entries processed\n",
      "2561000 entries processed\n",
      "2562000 entries processed\n",
      "2563000 entries processed\n",
      "2564000 entries processed\n",
      "2565000 entries processed\n",
      "2566000 entries processed\n",
      "2567000 entries processed\n",
      "2568000 entries processed\n",
      "2569000 entries processed\n",
      "2570000 entries processed\n",
      "2572000 entries processed\n",
      "2573000 entries processed\n",
      "2574000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/endDate>\n",
      "2575000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/endYearOfInsertion>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/endYearOfSales>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/endowment>\n",
      "2582000 entries processed\n",
      "2583000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/episodeNumber>\n",
      "2584000 entries processed\n",
      "2585000 entries processed\n",
      "2586000 entries processed\n",
      "2587000 entries processed\n",
      "2588000 entries processed\n",
      "2589000 entries processed\n",
      "2590000 entries processed\n",
      "2591000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/equity>\n",
      "2592000 entries processed\n",
      "2593000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/eruptionYear>\n",
      "2594000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/escapeVelocity>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/espnId>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/ethnicGroupsInYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/extinctionDate>\n",
      "2595000 entries processed\n",
      "2596000 entries processed\n",
      "2597000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/extinctionYear>\n",
      "2598000 entries processed\n",
      "2599000 entries processed\n",
      "2600000 entries processed\n",
      "2601000 entries processed\n",
      "2602000 entries processed\n",
      "2603000 entries processed\n",
      "2604000 entries processed\n",
      "2605000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/facilityId>\n",
      "2606000 entries processed\n",
      "2607000 entries processed\n",
      "2608000 entries processed\n",
      "2609000 entries processed\n",
      "2610000 entries processed\n",
      "2611000 entries processed\n",
      "2612000 entries processed\n",
      "2613000 entries processed\n",
      "2614000 entries processed\n",
      "2615000 entries processed\n",
      "2616000 entries processed\n",
      "2617000 entries processed\n",
      "2618000 entries processed\n",
      "2619000 entries processed\n",
      "2620000 entries processed\n",
      "2621000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/facultySize>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622000 entries processed\n",
      "2623000 entries processed\n",
      "2624000 entries processed\n",
      "2625000 entries processed\n",
      "2626000 entries processed\n",
      "2627000 entries processed\n",
      "2628000 entries processed\n",
      "2629000 entries processed\n",
      "2630000 entries processed\n",
      "2631000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/failedLaunches>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/fastestLap>\n",
      "2632000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/fat>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/feastDay>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/fees>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/fileSize>\n",
      "2633000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/finalFlight>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/finalPublicationYear>\n",
      "2634000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstAirDate>\n",
      "2635000 entries processed\n",
      "2636000 entries processed\n",
      "2637000 entries processed\n",
      "2638000 entries processed\n",
      "2639000 entries processed\n",
      "2640000 entries processed\n",
      "2641000 entries processed\n",
      "2642000 entries processed\n",
      "2643000 entries processed\n",
      "2644000 entries processed\n",
      "2645000 entries processed\n",
      "2646000 entries processed\n",
      "2647000 entries processed\n",
      "2648000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstAscentYear>\n",
      "2649000 entries processed\n",
      "2650000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstFlightEndDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstFlightStartDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstLaunchDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstPublicationDate>\n",
      "2651000 entries processed\n",
      "2652000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/firstPublicationYear>\n",
      "2653000 entries processed\n",
      "2654000 entries processed\n",
      "2655000 entries processed\n",
      "2656000 entries processed\n",
      "2657000 entries processed\n",
      "2658000 entries processed\n",
      "2659000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/floodingDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/floorArea>\n",
      "2660000 entries processed\n",
      "2661000 entries processed\n",
      "2662000 entries processed\n",
      "2663000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/floorCount>\n",
      "2664000 entries processed\n",
      "2665000 entries processed\n",
      "2666000 entries processed\n",
      "2667000 entries processed\n",
      "2668000 entries processed\n",
      "2669000 entries processed\n",
      "2670000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/foalDate>\n",
      "2671000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/formationDate>\n",
      "2672000 entries processed\n",
      "2673000 entries processed\n",
      "2674000 entries processed\n",
      "2675000 entries processed\n",
      "2676000 entries processed\n",
      "2677000 entries processed\n",
      "2678000 entries processed\n",
      "2679000 entries processed\n",
      "2680000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/formationYear>\n",
      "2681000 entries processed\n",
      "2682000 entries processed\n",
      "2683000 entries processed\n",
      "2684000 entries processed\n",
      "2685000 entries processed\n",
      "2686000 entries processed\n",
      "2687000 entries processed\n",
      "2688000 entries processed\n",
      "2689000 entries processed\n",
      "2690000 entries processed\n",
      "2691000 entries processed\n",
      "2692000 entries processed\n",
      "2693000 entries processed\n",
      "2694000 entries processed\n",
      "2695000 entries processed\n",
      "2696000 entries processed\n",
      "2697000 entries processed\n",
      "2698000 entries processed\n",
      "2699000 entries processed\n",
      "2700000 entries processed\n",
      "2701000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/foundingDate>\n",
      "2702000 entries processed\n",
      "2703000 entries processed\n",
      "2704000 entries processed\n",
      "2705000 entries processed\n",
      "2706000 entries processed\n",
      "2707000 entries processed\n",
      "2708000 entries processed\n",
      "2709000 entries processed\n",
      "2710000 entries processed\n",
      "2711000 entries processed\n",
      "2712000 entries processed\n",
      "2713000 entries processed\n",
      "2714000 entries processed\n",
      "2715000 entries processed\n",
      "2716000 entries processed\n",
      "2717000 entries processed\n",
      "2718000 entries processed\n",
      "2719000 entries processed\n",
      "2720000 entries processed\n",
      "2721000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2722000 entries processed\n",
      "2723000 entries processed\n",
      "2724000 entries processed\n",
      "2725000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/foundingYear>\n",
      "2726000 entries processed\n",
      "2727000 entries processed\n",
      "2728000 entries processed\n",
      "2729000 entries processed\n",
      "2730000 entries processed\n",
      "2731000 entries processed\n",
      "2732000 entries processed\n",
      "2733000 entries processed\n",
      "2734000 entries processed\n",
      "2735000 entries processed\n",
      "2736000 entries processed\n",
      "2737000 entries processed\n",
      "2738000 entries processed\n",
      "2740000 entries processed\n",
      "2741000 entries processed\n",
      "2742000 entries processed\n",
      "2743000 entries processed\n",
      "2744000 entries processed\n",
      "2745000 entries processed\n",
      "2746000 entries processed\n",
      "2747000 entries processed\n",
      "2748000 entries processed\n",
      "2749000 entries processed\n",
      "2750000 entries processed\n",
      "2751000 entries processed\n",
      "2752000 entries processed\n",
      "2753000 entries processed\n",
      "2754000 entries processed\n",
      "2755000 entries processed\n",
      "2756000 entries processed\n",
      "2757000 entries processed\n",
      "2758000 entries processed\n",
      "2759000 entries processed\n",
      "2760000 entries processed\n",
      "2761000 entries processed\n",
      "2762000 entries processed\n",
      "2763000 entries processed\n",
      "2764000 entries processed\n",
      "2765000 entries processed\n",
      "2766000 entries processed\n",
      "2767000 entries processed\n",
      "2768000 entries processed\n",
      "2769000 entries processed\n",
      "2770000 entries processed\n",
      "2771000 entries processed\n",
      "2772000 entries processed\n",
      "2773000 entries processed\n",
      "2774000 entries processed\n",
      "2775000 entries processed\n",
      "2776000 entries processed\n",
      "2777000 entries processed\n",
      "2778000 entries processed\n",
      "2779000 entries processed\n",
      "2780000 entries processed\n",
      "2781000 entries processed\n",
      "2782000 entries processed\n",
      "2783000 entries processed\n",
      "2784000 entries processed\n",
      "2785000 entries processed\n",
      "2786000 entries processed\n",
      "2787000 entries processed\n",
      "2788000 entries processed\n",
      "2789000 entries processed\n",
      "2790000 entries processed\n",
      "2791000 entries processed\n",
      "2792000 entries processed\n",
      "2793000 entries processed\n",
      "2794000 entries processed\n",
      "2795000 entries processed\n",
      "2796000 entries processed\n",
      "2797000 entries processed\n",
      "2798000 entries processed\n",
      "2799000 entries processed\n",
      "2800000 entries processed\n",
      "2801000 entries processed\n",
      "2802000 entries processed\n",
      "2803000 entries processed\n",
      "2804000 entries processed\n",
      "2805000 entries processed\n",
      "2806000 entries processed\n",
      "2807000 entries processed\n",
      "2808000 entries processed\n",
      "2809000 entries processed\n",
      "2810000 entries processed\n",
      "2811000 entries processed\n",
      "2812000 entries processed\n",
      "2813000 entries processed\n",
      "2814000 entries processed\n",
      "2815000 entries processed\n",
      "2816000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/frequency>\n",
      "2817000 entries processed\n",
      "2818000 entries processed\n",
      "2819000 entries processed\n",
      "2820000 entries processed\n",
      "2821000 entries processed\n",
      "2822000 entries processed\n",
      "2823000 entries processed\n",
      "2824000 entries processed\n",
      "2825000 entries processed\n",
      "2826000 entries processed\n",
      "2827000 entries processed\n",
      "2828000 entries processed\n",
      "2829000 entries processed\n",
      "2830000 entries processed\n",
      "2831000 entries processed\n",
      "2832000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/fuelCapacity>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/geneLocationEnd>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/geneLocationStart>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/glycemicIndex>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/governmentElevation>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/grayPage>\n",
      "2833000 entries processed\n",
      "2834000 entries processed\n",
      "2835000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/graySubject>\n",
      "2836000 entries processed\n",
      "2837000 entries processed\n",
      "2838000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/gross>\n",
      "2839000 entries processed\n",
      "2840000 entries processed\n",
      "2841000 entries processed\n",
      "2842000 entries processed\n",
      "2843000 entries processed\n",
      "2844000 entries processed\n",
      "2845000 entries processed\n",
      "2846000 entries processed\n",
      "2847000 entries processed\n",
      "2848000 entries processed\n",
      "2849000 entries processed\n",
      "2850000 entries processed\n",
      "2851000 entries processed\n",
      "2852000 entries processed\n",
      "2853000 entries processed\n",
      "2854000 entries processed\n",
      "2855000 entries processed\n",
      "2856000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/grossDomesticProduct>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/height>\n",
      "2857000 entries processed\n",
      "2858000 entries processed\n",
      "2859000 entries processed\n",
      "2863000 entries processed\n",
      "2864000 entries processed\n",
      "2865000 entries processed\n",
      "2866000 entries processed\n",
      "2867000 entries processed\n",
      "2868000 entries processed\n",
      "2869000 entries processed\n",
      "2870000 entries processed\n",
      "2871000 entries processed\n",
      "2872000 entries processed\n",
      "2873000 entries processed\n",
      "2874000 entries processed\n",
      "2876000 entries processed\n",
      "2877000 entries processed\n",
      "2878000 entries processed\n",
      "2879000 entries processed\n",
      "2880000 entries processed\n",
      "2881000 entries processed\n",
      "2882000 entries processed\n",
      "2883000 entries processed\n",
      "2884000 entries processed\n",
      "2885000 entries processed\n",
      "2886000 entries processed\n",
      "2887000 entries processed\n",
      "2888000 entries processed\n",
      "2889000 entries processed\n",
      "2890000 entries processed\n",
      "2891000 entries processed\n",
      "2892000 entries processed\n",
      "2893000 entries processed\n",
      "2894000 entries processed\n",
      "2895000 entries processed\n",
      "2896000 entries processed\n",
      "2897000 entries processed\n",
      "2898000 entries processed\n",
      "2899000 entries processed\n",
      "2900000 entries processed\n",
      "2901000 entries processed\n",
      "2902000 entries processed\n",
      "2903000 entries processed\n",
      "2904000 entries processed\n",
      "2905000 entries processed\n",
      "2906000 entries processed\n",
      "2907000 entries processed\n",
      "2908000 entries processed\n",
      "2909000 entries processed\n",
      "2910000 entries processed\n",
      "2911000 entries processed\n",
      "2912000 entries processed\n",
      "2913000 entries processed\n",
      "2914000 entries processed\n",
      "2915000 entries processed\n",
      "2916000 entries processed\n",
      "2917000 entries processed\n",
      "2918000 entries processed\n",
      "2919000 entries processed\n",
      "2920000 entries processed\n",
      "2921000 entries processed\n",
      "2922000 entries processed\n",
      "2923000 entries processed\n",
      "2924000 entries processed\n",
      "2925000 entries processed\n",
      "2926000 entries processed\n",
      "2927000 entries processed\n",
      "2928000 entries processed\n",
      "2929000 entries processed\n",
      "2930000 entries processed\n",
      "2931000 entries processed\n",
      "2932000 entries processed\n",
      "2933000 entries processed\n",
      "2934000 entries processed\n",
      "2935000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2936000 entries processed\n",
      "2937000 entries processed\n",
      "2938000 entries processed\n",
      "2939000 entries processed\n",
      "2940000 entries processed\n",
      "2941000 entries processed\n",
      "2942000 entries processed\n",
      "2943000 entries processed\n",
      "2944000 entries processed\n",
      "2945000 entries processed\n",
      "2946000 entries processed\n",
      "2947000 entries processed\n",
      "2948000 entries processed\n",
      "2949000 entries processed\n",
      "2950000 entries processed\n",
      "2951000 entries processed\n",
      "2952000 entries processed\n",
      "2953000 entries processed\n",
      "2955000 entries processed\n",
      "2956000 entries processed\n",
      "2957000 entries processed\n",
      "2958000 entries processed\n",
      "2959000 entries processed\n",
      "2960000 entries processed\n",
      "2961000 entries processed\n",
      "2962000 entries processed\n",
      "2963000 entries processed\n",
      "2964000 entries processed\n",
      "2965000 entries processed\n",
      "2966000 entries processed\n",
      "2967000 entries processed\n",
      "2968000 entries processed\n",
      "2969000 entries processed\n",
      "2970000 entries processed\n",
      "2971000 entries processed\n",
      "2972000 entries processed\n",
      "2973000 entries processed\n",
      "2974000 entries processed\n",
      "2975000 entries processed\n",
      "2976000 entries processed\n",
      "2977000 entries processed\n",
      "2978000 entries processed\n",
      "2979000 entries processed\n",
      "2980000 entries processed\n",
      "2981000 entries processed\n",
      "2982000 entries processed\n",
      "2983000 entries processed\n",
      "2984000 entries processed\n",
      "2985000 entries processed\n",
      "2986000 entries processed\n",
      "2987000 entries processed\n",
      "2988000 entries processed\n",
      "2989000 entries processed\n",
      "2990000 entries processed\n",
      "2991000 entries processed\n",
      "2992000 entries processed\n",
      "2993000 entries processed\n",
      "2994000 entries processed\n",
      "2995000 entries processed\n",
      "2996000 entries processed\n",
      "2997000 entries processed\n",
      "2998000 entries processed\n",
      "2999000 entries processed\n",
      "3000000 entries processed\n",
      "3001000 entries processed\n",
      "3002000 entries processed\n",
      "3003000 entries processed\n",
      "3004000 entries processed\n",
      "3005000 entries processed\n",
      "3006000 entries processed\n",
      "3007000 entries processed\n",
      "3008000 entries processed\n",
      "3009000 entries processed\n",
      "3010000 entries processed\n",
      "3011000 entries processed\n",
      "3012000 entries processed\n",
      "3013000 entries processed\n",
      "3014000 entries processed\n",
      "3015000 entries processed\n",
      "3016000 entries processed\n",
      "3017000 entries processed\n",
      "3018000 entries processed\n",
      "3019000 entries processed\n",
      "3020000 entries processed\n",
      "3021000 entries processed\n",
      "3022000 entries processed\n",
      "3023000 entries processed\n",
      "3024000 entries processed\n",
      "3025000 entries processed\n",
      "3026000 entries processed\n",
      "3027000 entries processed\n",
      "3028000 entries processed\n",
      "3029000 entries processed\n",
      "3030000 entries processed\n",
      "3031000 entries processed\n",
      "3032000 entries processed\n",
      "3033000 entries processed\n",
      "3034000 entries processed\n",
      "3035000 entries processed\n",
      "3036000 entries processed\n",
      "3037000 entries processed\n",
      "3038000 entries processed\n",
      "3039000 entries processed\n",
      "3040000 entries processed\n",
      "3041000 entries processed\n",
      "3042000 entries processed\n",
      "3043000 entries processed\n",
      "3044000 entries processed\n",
      "3045000 entries processed\n",
      "3046000 entries processed\n",
      "3047000 entries processed\n",
      "3048000 entries processed\n",
      "3049000 entries processed\n",
      "3050000 entries processed\n",
      "3051000 entries processed\n",
      "3052000 entries processed\n",
      "3053000 entries processed\n",
      "3054000 entries processed\n",
      "3055000 entries processed\n",
      "3056000 entries processed\n",
      "3057000 entries processed\n",
      "3058000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/heightAboveAverageTerrain>\n",
      "3059000 entries processed\n",
      "3060000 entries processed\n",
      "3061000 entries processed\n",
      "3062000 entries processed\n",
      "3063000 entries processed\n",
      "3064000 entries processed\n",
      "3065000 entries processed\n",
      "3066000 entries processed\n",
      "3067000 entries processed\n",
      "3068000 entries processed\n",
      "3069000 entries processed\n",
      "3070000 entries processed\n",
      "3071000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/highestBreak>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/highestRank>\n",
      "3072000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/hipSize>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/hsvCoordinateHue>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/hsvCoordinateSaturation>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/hsvCoordinateValue>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/imageSize>\n",
      "3076000 entries processed\n",
      "3077000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/impactFactor>\n",
      "3078000 entries processed\n",
      "3079000 entries processed\n",
      "3080000 entries processed\n",
      "3081000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/impactFactorAsOf>\n",
      "3082000 entries processed\n",
      "3083000 entries processed\n",
      "3084000 entries processed\n",
      "3085000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/installedCapacity>\n",
      "3086000 entries processed\n",
      "3087000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/introduced>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/introductionDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/issDockings>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastAirDate>\n",
      "3088000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastElectionDate>\n",
      "3089000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastFlightEndDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastFlightStartDate>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastLaunchDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastPosition>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lastPublicationDate>\n",
      "3091000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/latestPreviewDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/latestReleaseDate>\n",
      "3092000 entries processed\n",
      "3093000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/launches>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/layingDown>\n",
      "3094000 entries processed\n",
      "3095000 entries processed\n",
      "3096000 entries processed\n",
      "3097000 entries processed\n",
      "3098000 entries processed\n",
      "3099000 entries processed\n",
      "3100000 entries processed\n",
      "3101000 entries processed\n",
      "3102000 entries processed\n",
      "3103000 entries processed\n",
      "3104000 entries processed\n",
      "3105000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/length>\n",
      "3106000 entries processed\n",
      "3107000 entries processed\n",
      "3108000 entries processed\n",
      "3109000 entries processed\n",
      "3110000 entries processed\n",
      "3112000 entries processed\n",
      "3113000 entries processed\n",
      "3114000 entries processed\n",
      "3115000 entries processed\n",
      "3116000 entries processed\n",
      "3117000 entries processed\n",
      "3118000 entries processed\n",
      "3119000 entries processed\n",
      "3120000 entries processed\n",
      "3121000 entries processed\n",
      "3122000 entries processed\n",
      "3123000 entries processed\n",
      "3124000 entries processed\n",
      "3125000 entries processed\n",
      "3126000 entries processed\n",
      "3127000 entries processed\n",
      "3128000 entries processed\n",
      "3129000 entries processed\n",
      "3130000 entries processed\n",
      "3131000 entries processed\n",
      "3132000 entries processed\n",
      "3133000 entries processed\n",
      "3134000 entries processed\n",
      "3135000 entries processed\n",
      "3136000 entries processed\n",
      "3137000 entries processed\n",
      "3138000 entries processed\n",
      "3139000 entries processed\n",
      "3140000 entries processed\n",
      "3141000 entries processed\n",
      "3142000 entries processed\n",
      "3143000 entries processed\n",
      "3144000 entries processed\n",
      "3145000 entries processed\n",
      "3146000 entries processed\n",
      "3147000 entries processed\n",
      "3148000 entries processed\n",
      "3149000 entries processed\n",
      "3150000 entries processed\n",
      "3151000 entries processed\n",
      "3152000 entries processed\n",
      "3153000 entries processed\n",
      "3154000 entries processed\n",
      "3155000 entries processed\n",
      "3156000 entries processed\n",
      "3157000 entries processed\n",
      "3158000 entries processed\n",
      "3159000 entries processed\n",
      "3160000 entries processed\n",
      "3161000 entries processed\n",
      "3162000 entries processed\n",
      "3163000 entries processed\n",
      "3164000 entries processed\n",
      "3165000 entries processed\n",
      "3166000 entries processed\n",
      "3167000 entries processed\n",
      "3168000 entries processed\n",
      "3169000 entries processed\n",
      "3170000 entries processed\n",
      "3171000 entries processed\n",
      "3172000 entries processed\n",
      "3173000 entries processed\n",
      "3174000 entries processed\n",
      "3175000 entries processed\n",
      "3176000 entries processed\n",
      "3177000 entries processed\n",
      "3178000 entries processed\n",
      "3179000 entries processed\n",
      "3180000 entries processed\n",
      "3181000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lineLength>\n",
      "3182000 entries processed\n",
      "3183000 entries processed\n",
      "3184000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/loadLimit>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lowerAge>\n",
      "3185000 entries processed\n",
      "3186000 entries processed\n",
      "3187000 entries processed\n",
      "3188000 entries processed\n",
      "3189000 entries processed\n",
      "3190000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/lowerEarthOrbitPayload>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maidenFlight>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maidenVoyage>\n",
      "3191000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/mainspan>\n",
      "3192000 entries processed\n",
      "3193000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/managementElevation>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/mass>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maxTime>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maximumBoatBeam>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maximumBoatLength>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maximumDepth>\n",
      "3194000 entries processed\n",
      "3195000 entries processed\n",
      "3196000 entries processed\n",
      "3197000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maximumDischarge>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/maximumElevation>\n",
      "3199000 entries processed\n",
      "3200000 entries processed\n",
      "3201000 entries processed\n",
      "3202000 entries processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5836000 entries processed\n",
      "5838000 entries processed\n",
      "5839000 entries processed\n",
      "5840000 entries processed\n",
      "5841000 entries processed\n",
      "5842000 entries processed\n",
      "5843000 entries processed\n",
      "5845000 entries processed\n",
      "5846000 entries processed\n",
      "5847000 entries processed\n",
      "5848000 entries processed\n",
      "5849000 entries processed\n",
      "5850000 entries processed\n",
      "5852000 entries processed\n",
      "5853000 entries processed\n",
      "5854000 entries processed\n",
      "5855000 entries processed\n",
      "5856000 entries processed\n",
      "5857000 entries processed\n",
      "5858000 entries processed\n",
      "5859000 entries processed\n",
      "5860000 entries processed\n",
      "5861000 entries processed\n",
      "5862000 entries processed\n",
      "5863000 entries processed\n",
      "5865000 entries processed\n",
      "5866000 entries processed\n",
      "5867000 entries processed\n",
      "5868000 entries processed\n",
      "5869000 entries processed\n",
      "5870000 entries processed\n",
      "5871000 entries processed\n",
      "5872000 entries processed\n",
      "5873000 entries processed\n",
      "5874000 entries processed\n",
      "5875000 entries processed\n",
      "5876000 entries processed\n",
      "5877000 entries processed\n",
      "5878000 entries processed\n",
      "5879000 entries processed\n",
      "5880000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/runwayLength>\n",
      "5881000 entries processed\n",
      "5884000 entries processed\n",
      "5885000 entries processed\n",
      "5886000 entries processed\n",
      "5887000 entries processed\n",
      "5888000 entries processed\n",
      "5889000 entries processed\n",
      "5890000 entries processed\n",
      "5891000 entries processed\n",
      "5892000 entries processed\n",
      "5893000 entries processed\n",
      "5894000 entries processed\n",
      "5895000 entries processed\n",
      "5896000 entries processed\n",
      "5897000 entries processed\n",
      "5898000 entries processed\n",
      "5899000 entries processed\n",
      "5900000 entries processed\n",
      "5901000 entries processed\n",
      "5902000 entries processed\n",
      "5903000 entries processed\n",
      "5904000 entries processed\n",
      "5905000 entries processed\n",
      "5906000 entries processed\n",
      "5907000 entries processed\n",
      "5908000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/salary>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/satellitesDeployed>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/seasonNumber>\n",
      "5909000 entries processed\n",
      "5910000 entries processed\n",
      "5911000 entries processed\n",
      "5912000 entries processed\n",
      "5913000 entries processed\n",
      "5914000 entries processed\n",
      "5915000 entries processed\n",
      "5916000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/seatingCapacity>\n",
      "5917000 entries processed\n",
      "5918000 entries processed\n",
      "5919000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/serviceEndYear>\n",
      "5920000 entries processed\n",
      "5921000 entries processed\n",
      "5922000 entries processed\n",
      "5923000 entries processed\n",
      "5924000 entries processed\n",
      "5925000 entries processed\n",
      "5926000 entries processed\n",
      "5927000 entries processed\n",
      "5928000 entries processed\n",
      "5929000 entries processed\n",
      "5930000 entries processed\n",
      "5931000 entries processed\n",
      "5932000 entries processed\n",
      "5933000 entries processed\n",
      "5934000 entries processed\n",
      "5935000 entries processed\n",
      "5936000 entries processed\n",
      "5937000 entries processed\n",
      "5938000 entries processed\n",
      "5939000 entries processed\n",
      "5940000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/serviceStartYear>\n",
      "5941000 entries processed\n",
      "5942000 entries processed\n",
      "5943000 entries processed\n",
      "5944000 entries processed\n",
      "5945000 entries processed\n",
      "5946000 entries processed\n",
      "5947000 entries processed\n",
      "5948000 entries processed\n",
      "5949000 entries processed\n",
      "5950000 entries processed\n",
      "5951000 entries processed\n",
      "5952000 entries processed\n",
      "5953000 entries processed\n",
      "5954000 entries processed\n",
      "5955000 entries processed\n",
      "5956000 entries processed\n",
      "5957000 entries processed\n",
      "5958000 entries processed\n",
      "5959000 entries processed\n",
      "5960000 entries processed\n",
      "5961000 entries processed\n",
      "5962000 entries processed\n",
      "5963000 entries processed\n",
      "5964000 entries processed\n",
      "5965000 entries processed\n",
      "5966000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/servingSize>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shareDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shareOfAudience>\n",
      "5967000 entries processed\n",
      "5968000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shipBeam>\n",
      "5969000 entries processed\n",
      "5970000 entries processed\n",
      "5971000 entries processed\n",
      "5972000 entries processed\n",
      "5973000 entries processed\n",
      "5974000 entries processed\n",
      "5975000 entries processed\n",
      "5976000 entries processed\n",
      "5977000 entries processed\n",
      "5978000 entries processed\n",
      "5979000 entries processed\n",
      "5980000 entries processed\n",
      "5981000 entries processed\n",
      "5982000 entries processed\n",
      "5983000 entries processed\n",
      "5984000 entries processed\n",
      "5985000 entries processed\n",
      "5986000 entries processed\n",
      "5987000 entries processed\n",
      "5988000 entries processed\n",
      "5989000 entries processed\n",
      "5990000 entries processed\n",
      "5991000 entries processed\n",
      "5992000 entries processed\n",
      "5993000 entries processed\n",
      "5994000 entries processed\n",
      "5995000 entries processed\n",
      "5996000 entries processed\n",
      "5997000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shipDisplacement>\n",
      "5998000 entries processed\n",
      "5999000 entries processed\n",
      "6000000 entries processed\n",
      "6001000 entries processed\n",
      "6002000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shipDraft>\n",
      "6003000 entries processed\n",
      "6004000 entries processed\n",
      "6005000 entries processed\n",
      "6006000 entries processed\n",
      "6007000 entries processed\n",
      "6008000 entries processed\n",
      "6009000 entries processed\n",
      "6010000 entries processed\n",
      "6011000 entries processed\n",
      "6012000 entries processed\n",
      "6013000 entries processed\n",
      "6014000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shipLaunch>\n",
      "6015000 entries processed\n",
      "6016000 entries processed\n",
      "6017000 entries processed\n",
      "6018000 entries processed\n",
      "6019000 entries processed\n",
      "6020000 entries processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6021000 entries processed\n",
      "6022000 entries processed\n",
      "6023000 entries processed\n",
      "6024000 entries processed\n",
      "6025000 entries processed\n",
      "6026000 entries processed\n",
      "6027000 entries processed\n",
      "6028000 entries processed\n",
      "6029000 entries processed\n",
      "6030000 entries processed\n",
      "6031000 entries processed\n",
      "6032000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shoeNumber>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/shoreLength>\n",
      "6033000 entries processed\n",
      "6034000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/sourceConfluenceElevation>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/sourceElevation>\n",
      "6035000 entries processed\n",
      "6036000 entries processed\n",
      "6037000 entries processed\n",
      "6038000 entries processed\n",
      "6039000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/speaker>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/speedLimit>\n",
      "6040000 entries processed\n",
      "6041000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/squadNumber>\n",
      "6119000 entries processed\n",
      "6125000 entries processed\n",
      "6139000 entries processed\n",
      "6166000 entries processed\n",
      "6168000 entries processed\n",
      "6214000 entries processed\n",
      "6217000 entries processed\n",
      "6222000 entries processed\n",
      "6234000 entries processed\n",
      "6244000 entries processed\n",
      "6252000 entries processed\n",
      "6258000 entries processed\n",
      "6271000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/staff>\n",
      "6287000 entries processed\n",
      "6288000 entries processed\n",
      "6289000 entries processed\n",
      "6290000 entries processed\n",
      "6291000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/startDate>\n",
      "6292000 entries processed\n",
      "6293000 entries processed\n",
      "6294000 entries processed\n",
      "6295000 entries processed\n",
      "6296000 entries processed\n",
      "6297000 entries processed\n",
      "6298000 entries processed\n",
      "6299000 entries processed\n",
      "6300000 entries processed\n",
      "6301000 entries processed\n",
      "6302000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/startYearOfInsertion>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/startYearOfSales>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/statisticValue>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/statisticYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/subdivisions>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/suborbitalFlights>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/successfulLaunches>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/supplementalDraftYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/suppreddedDate>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/surfaceArea>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/teamSize>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/temperature>\n",
      "6310000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/testaverage>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/timeInSpace>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/toll>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/topSpeed>\n",
      "6311000 entries processed\n",
      "6312000 entries processed\n",
      "6313000 entries processed\n",
      "6314000 entries processed\n",
      "6315000 entries processed\n",
      "6316000 entries processed\n",
      "6317000 entries processed\n",
      "6318000 entries processed\n",
      "6319000 entries processed\n",
      "6320000 entries processed\n",
      "6321000 entries processed\n",
      "6322000 entries processed\n",
      "6323000 entries processed\n",
      "6324000 entries processed\n",
      "6325000 entries processed\n",
      "6326000 entries processed\n",
      "6327000 entries processed\n",
      "6328000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/torqueOutput>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/totalLaunches>\n",
      "6332000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/totalPopulation>\n",
      "6333000 entries processed\n",
      "6334000 entries processed\n",
      "6335000 entries processed\n",
      "6336000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/totalTravellers>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/trackLength>\n",
      "6337000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/trackNumber>\n",
      "6338000 entries processed\n",
      "6339000 entries processed\n",
      "6340000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/tuition>\n",
      "6341000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/undraftedYear>\n",
      "6342000 entries processed\n",
      "6343000 entries processed\n",
      "6344000 entries processed\n",
      "6345000 entries processed\n",
      "6346000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/unitCost>\n",
      "6347000 entries processed\n",
      "6348000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/upperAge>\n",
      "6349000 entries processed\n",
      "6350000 entries processed\n",
      "6351000 entries processed\n",
      "6352000 entries processed\n",
      "6353000 entries processed\n",
      "6354000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/usSales>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/vehiclesPerDay>\n",
      "6356000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/visitorStatisticsAsOf>\n",
      "6357000 entries processed\n",
      "6358000 entries processed\n",
      "6359000 entries processed\n",
      "6360000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/visitorsPerYear>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/visitorsPercentageChange>\n",
      "6361000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/voltageOfElectrification>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/volume>\n",
      "6362000 entries processed\n",
      "6363000 entries processed\n",
      "6364000 entries processed\n",
      "6366000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/waistSize>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/watershed>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/wavelength>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/weight>\n",
      "6369000 entries processed\n",
      "6370000 entries processed\n",
      "6371000 entries processed\n",
      "6372000 entries processed\n",
      "6373000 entries processed\n",
      "6375000 entries processed\n",
      "6376000 entries processed\n",
      "6377000 entries processed\n",
      "6378000 entries processed\n",
      "6379000 entries processed\n",
      "6380000 entries processed\n",
      "6381000 entries processed\n",
      "6382000 entries processed\n",
      "6383000 entries processed\n",
      "6384000 entries processed\n",
      "6385000 entries processed\n",
      "6386000 entries processed\n",
      "6387000 entries processed\n",
      "6388000 entries processed\n",
      "6389000 entries processed\n",
      "6390000 entries processed\n",
      "6391000 entries processed\n",
      "6392000 entries processed\n",
      "6393000 entries processed\n",
      "6394000 entries processed\n",
      "6395000 entries processed\n",
      "6396000 entries processed\n",
      "6397000 entries processed\n",
      "6398000 entries processed\n",
      "6399000 entries processed\n",
      "6400000 entries processed\n",
      "6401000 entries processed\n",
      "6402000 entries processed\n",
      "6403000 entries processed\n",
      "6404000 entries processed\n",
      "6405000 entries processed\n",
      "6406000 entries processed\n",
      "6407000 entries processed\n",
      "6408000 entries processed\n",
      "6409000 entries processed\n",
      "6410000 entries processed\n",
      "6411000 entries processed\n",
      "6412000 entries processed\n",
      "6413000 entries processed\n",
      "6414000 entries processed\n",
      "6415000 entries processed\n",
      "6416000 entries processed\n",
      "6417000 entries processed\n",
      "6418000 entries processed\n",
      "6419000 entries processed\n",
      "6420000 entries processed\n",
      "6421000 entries processed\n",
      "6422000 entries processed\n",
      "6423000 entries processed\n",
      "6424000 entries processed\n",
      "6425000 entries processed\n",
      "6426000 entries processed\n",
      "6427000 entries processed\n",
      "6428000 entries processed\n",
      "6429000 entries processed\n",
      "6430000 entries processed\n",
      "6431000 entries processed\n",
      "6432000 entries processed\n",
      "6433000 entries processed\n",
      "6434000 entries processed\n",
      "6435000 entries processed\n",
      "6436000 entries processed\n",
      "6437000 entries processed\n",
      "6438000 entries processed\n",
      "6439000 entries processed\n",
      "6440000 entries processed\n",
      "6441000 entries processed\n",
      "6442000 entries processed\n",
      "6443000 entries processed\n",
      "6444000 entries processed\n",
      "6445000 entries processed\n",
      "6446000 entries processed\n",
      "6447000 entries processed\n",
      "6448000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/wheelbase>\n",
      "6450000 entries processed\n",
      "6452000 entries processed\n",
      "6453000 entries processed\n",
      "6454000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/width>\n",
      "6455000 entries processed\n",
      "6456000 entries processed\n",
      "6457000 entries processed\n",
      "6458000 entries processed\n",
      "6460000 entries processed\n",
      "6462000 entries processed\n",
      "6463000 entries processed\n",
      "6464000 entries processed\n",
      "6465000 entries processed\n",
      "6466000 entries processed\n",
      "6467000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/wins>\n",
      "6468000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/year>\n",
      "6473000 entries processed\n",
      "6474000 entries processed\n",
      "6475000 entries processed\n",
      "6476000 entries processed\n",
      "6477000 entries processed\n",
      "6479000 entries processed\n",
      "6480000 entries processed\n",
      "6481000 entries processed\n",
      "6482000 entries processed\n",
      "6483000 entries processed\n",
      "6484000 entries processed\n",
      "6485000 entries processed\n",
      "6486000 entries processed\n",
      "6487000 entries processed\n",
      "6488000 entries processed\n",
      "6489000 entries processed\n",
      "6490000 entries processed\n",
      "6491000 entries processed\n",
      "6492000 entries processed\n",
      "6493000 entries processed\n",
      "6494000 entries processed\n",
      "6495000 entries processed\n",
      "6496000 entries processed\n",
      "6497000 entries processed\n",
      "6498000 entries processed\n",
      "6499000 entries processed\n",
      "6500000 entries processed\n",
      "6501000 entries processed\n",
      "6502000 entries processed\n",
      "6504000 entries processed\n",
      "6506000 entries processed\n",
      "6507000 entries processed\n",
      "6508000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/yearOfConstruction>\n",
      "6511000 entries processed\n",
      "6512000 entries processed\n",
      "6513000 entries processed\n",
      "6514000 entries processed\n",
      "6515000 entries processed\n",
      "6516000 entries processed\n",
      "6517000 entries processed\n",
      "6518000 entries processed\n",
      "6519000 entries processed\n",
      "6520000 entries processed\n",
      "6521000 entries processed\n",
      "6522000 entries processed\n",
      "6523000 entries processed\n",
      "6524000 entries processed\n",
      "6525000 entries processed\n",
      "6526000 entries processed\n",
      "6527000 entries processed\n",
      "6528000 entries processed\n",
      "6529000 entries processed\n",
      "6530000 entries processed\n",
      "6531000 entries processed\n",
      "6532000 entries processed\n",
      "6533000 entries processed\n",
      "6534000 entries processed\n",
      "6535000 entries processed\n",
      "6536000 entries processed\n",
      "6537000 entries processed\n",
      "6538000 entries processed\n",
      "6539000 entries processed\n",
      "6540000 entries processed\n",
      "6541000 entries processed\n",
      "6542000 entries processed\n",
      "6543000 entries processed\n",
      "6544000 entries processed\n",
      "6545000 entries processed\n",
      "6546000 entries processed\n",
      "6547000 entries processed\n",
      "6548000 entries processed\n",
      "6549000 entries processed\n",
      "6550000 entries processed\n",
      "6551000 entries processed\n",
      "6552000 entries processed\n",
      "6553000 entries processed\n",
      "6554000 entries processed\n",
      "6555000 entries processed\n",
      "6556000 entries processed\n",
      "6557000 entries processed\n",
      "6558000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/yearOfElectrification>\n",
      "6559000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://dbpedia.org/ontology/years>\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://www.w3.org/2003/01/geo/wgs84_pos#lat>\n",
      "7488000 entries processed\n",
      "7489000 entries processed\n",
      "7490000 entries processed\n",
      "7491000 entries processed\n",
      "Make new df...\n",
      "Clean df...\n",
      "Cleaning df...\n",
      "Convert dummies...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Save df...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Now solving <http://www.w3.org/2003/01/geo/wgs84_pos#long>\n",
      "7492000 entries processed\n",
      "7493000 entries processed\n",
      "7494000 entries processed\n",
      "7495000 entries processed\n",
      "Cleaning df...\n",
      "To sparse...\n",
      "apply tuple...\n",
      "calc group by columns...\n",
      "calc dummies...\n",
      "apply list...\n",
      "To dense...\n",
      "Saving df...\n",
      "Saved successfully\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "start_line = 0\n",
    "\n",
    "token_around_counter = collections.Counter()\n",
    "triples_file_filtered_sorted_by_relation.seek(0)\n",
    "prev = None\n",
    "for i, line in enumerate(triples_file_filtered_sorted_by_relation):    \n",
    "    if i < start_line:\n",
    "        continue\n",
    "    \n",
    "    triple = split_triple(line)\n",
    "    \n",
    "    if only_top20 and triple[1][1:-1] not in relations_top20:\n",
    "        continue\n",
    "    \n",
    "    if triple[1] != prev:\n",
    "        if prev != None:\n",
    "            save_name = short_name(prev[1:-1])\n",
    "            \n",
    "            print(\"Make new df...\")\n",
    "            df = make_new_df(rows, df_cols)\n",
    "            print(\"Clean df...\")\n",
    "            df = clean_df(df, True, save_name, None)\n",
    "            print(\"Convert dummies...\")\n",
    "            df = convert_to_df_with_dummies(df)\n",
    "            \n",
    "            print(\"Save df...\")\n",
    "            #print(df)\n",
    "            save_df(df, save_name)\n",
    "        #df = get_new_df()\n",
    "        rows = list()\n",
    "        print(\"Now solving \" + triple[1])\n",
    "    \n",
    "    \n",
    "    fact_number = triple[2].split(\"^^\")[0]\n",
    "    found = False\n",
    "    prev = triple[1]\n",
    "    try:\n",
    "        abstract = abstract_dict[triple[0]]\n",
    "    except KeyError:\n",
    "        #print('KeyError for ' + triple[0])\n",
    "        continue\n",
    "    \n",
    "    abstract_literals = abstract_get_literals(abstract, triple[0], local_signs, constants, True, date_dict)\n",
    "    \n",
    "    #print(abstract)\n",
    "    #print(abstract_literals)\n",
    "    \n",
    "    if relation_type_dict[triple[1][1:-1]] in types_int:\n",
    "        type_searched = type_int\n",
    "    elif relation_type_dict[triple[1][1:-1]] in types_float:\n",
    "        #Special case: If fact number is typed as double but is actually integer (e.g. 3E6)\n",
    "        if improve_float_matching and float(fact_number).is_integer():\n",
    "            fact_number = str(int(float(fact_number)))\n",
    "            type_searched = type_int\n",
    "        else:\n",
    "            type_searched = type_float\n",
    "    elif relation_type_dict[triple[1][1:-1]] in types_date:\n",
    "        type_searched = type_date\n",
    "    else:\n",
    "        print('There was some error that should not occur...')\n",
    "        continue\n",
    "        \n",
    "    #print(\"Looking for \" + fact_number + \"(\" + type_searched + \")\")\n",
    "        \n",
    "    found_somewhere = False\n",
    "    \n",
    "    int_list_abstract = [[t for t in sent if t[2] == type_int] for sent in abstract_literals]\n",
    "    float_list_abstract = [[t for t in sent if t[2] == type_float] for sent in abstract_literals]\n",
    "    number_list_abstract = [[t for t in sent if t[2] == type_int or t[2] == type_float] for sent in abstract_literals]\n",
    "    date_list_abstract = [[t for t in sent if t[2] == type_date] for sent in abstract_literals]\n",
    "        \n",
    "    flat_index = 0 #-1\n",
    "    flat_index_number = 0 #-1\n",
    "    flat_index_fit = 0 #-1\n",
    "    \n",
    "    \n",
    "    for j, sentence in enumerate(abstract_literals):\n",
    "        \n",
    "        int_list_sentence = int_list_abstract[j]\n",
    "        float_list_sentence = float_list_abstract[j]\n",
    "        number_list_sentence = number_list_abstract[j]\n",
    "        date_list_sentence = date_list_abstract[j]\n",
    "        \n",
    "        k_fit = 0 #-1\n",
    "        k_number = 0 #-1\n",
    "        \n",
    "        for k, abstract_record in enumerate(sentence):\n",
    "\n",
    "            abstract_number_converted = handle_units(triple[1], type_searched, abstract_record, convert_units, use_gold_standard_units, constants, unit_dict, unit_conversion_dict, negative_dict)\n",
    "            \n",
    "            #None is returned whenever the type in abstract number does not fit the searched type (afer possible unit conversions)\n",
    "            if abstract_number_converted is not None:\n",
    "                \n",
    "                #print(str(abstract_number_converted) + ' is valid.')\n",
    "\n",
    "                found = False\n",
    "                if type_searched == type_int:\n",
    "                    match_result = matched_int(fact_number, abstract_number_converted)\n",
    "                elif type_searched == type_float:\n",
    "                    match_result = matched_float(fact_number, abstract_number_converted)\n",
    "                elif type_searched == type_date:\n",
    "                    match_result = matched_date(fact_number, abstract_number_converted)\n",
    "                else:\n",
    "                    raise ValueError('Invalid Type: ' + type_searched)\n",
    "\n",
    "\n",
    "                if match_result != 'Not matched':\n",
    "                    found = True\n",
    "                    found_somewhere = True\n",
    "                    matched_cnt[match_result] += 1                      \n",
    "\n",
    "                rows.append(create_record(int_list_abstract = int_list_abstract, \\\n",
    "                                          float_list_abstract = float_list_abstract, \\\n",
    "                                          number_list_abstract = number_list_abstract, \\\n",
    "                                          date_list_abstract = date_list_abstract, \\\n",
    "                                          int_list_sentence = int_list_sentence, \\\n",
    "                                          float_list_sentence = float_list_sentence, \\\n",
    "                                          number_list_sentence = number_list_sentence, \\\n",
    "                                          date_list_sentence = date_list_sentence, \\\n",
    "                                          index_abstract = j, \\\n",
    "                                          index_sentence = k, \\\n",
    "                                          index_sentence_fitting = k_fit, \\\n",
    "                                          index_sentence_number = k_number, \\\n",
    "                                          flat_index = flat_index, \\\n",
    "                                          flat_index_fitting = flat_index_fit, \\\n",
    "                                          flat_index_number = flat_index_number, \\\n",
    "                                          tokens_around = abstract_record[3], \\\n",
    "                                          token_directly_following = abstract_record[4], \\\n",
    "                                          found = found, \\\n",
    "                                          entity = triple[0], \\\n",
    "                                          relation = triple[1], \\\n",
    "                                          fact_number = fact_number, \\\n",
    "                                          abstract_number = abstract_record[0], \\\n",
    "                                          abstract_number_converted = abstract_number_converted, \\\n",
    "                                          matching_type = match_result, \\\n",
    "                                          global_offset = abstract_record[5], \\\n",
    "                                          relation_type = type_searched, \\\n",
    "                                          instance_types_dict = instance_types_dict, \\\n",
    "                                          relation_stat_dict = relation_stat_dict,\n",
    "                                          track_token_around_counter = True))\n",
    "            \n",
    "            flat_index += 1\n",
    "            \n",
    "            if abstract_record[2] == type_int or abstract_record[2] == type_float:\n",
    "                k_number +=1\n",
    "                flat_index_number += 1\n",
    "            \n",
    "            if abstract_record[2] == type_searched:\n",
    "                k_fit += 1\n",
    "                flat_index_fit += 1\n",
    "                \n",
    "    if not found_somewhere:\n",
    "        matched_cnt['Not matched'] += 1\n",
    "        \n",
    "    if i % 1000 == 0:\n",
    "        print(str(i) + \" entries processed\")\n",
    "        #print(\"Running Time for sentence parsing (nlp): \" + str(running_time) + \"ms\")\n",
    "\n",
    "save_name = short_name(prev[1:-1])\n",
    "df = make_new_df(rows, df_cols)\n",
    "df = clean_df(df, True, save_name, None)\n",
    "df = convert_to_df_with_dummies(df)\n",
    "save_df(df, save_name)   \n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T21:52:10.317414Z",
     "start_time": "2018-11-27T21:52:10.303419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Matched by range': 35164,\n",
       "         'Not matched': 3535012,\n",
       "         'Matched by equality': 281782,\n",
       "         'Matched by equality (date)': 912003,\n",
       "         'Matched by 2-Decimal round': 152,\n",
       "         'Matched by Mio round': 23,\n",
       "         'Matched by 100K round': 17,\n",
       "         'Matched by 10Mio round': 11,\n",
       "         'Matched by Mrd round': 2,\n",
       "         'Matched by 100Mio round': 3,\n",
       "         'Matched by Hundret round': 622,\n",
       "         'Matched by Thousand round': 253,\n",
       "         'Matched by 10K round': 62,\n",
       "         'Matched by 4-Decimal round': 1,\n",
       "         'Matched by 3-Decimal round': 11})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_cnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
